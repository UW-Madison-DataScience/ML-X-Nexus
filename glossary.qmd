---

title: Glossary of ML Terms
author: "ML+X"
order: 8
tbl-colwidths: [5,30]
date-modified: "last-modified"
date-format: long
---

::: column-screen-inset-right

### Glossary of ML Terms

| Term | Meaning | Application | Key Benefits | Common Libraries/Tools | Categories |
|:----:|:--------|:------------|:-------------|:-----------------------|:----------|
| ML | Machine learning | Study of statistical algorithms that can learn from data and generalize to unseen data | Facilitates discovery of complex patterns, enhances predictive modeling, enables large-scale data analysis | Scikit-learn, TensorFlow, PyTorch | General Concepts |
| EDA | Exploratory data analysis | Understanding data before modeling | Identifies patterns, detects anomalies, informs feature selection | Pandas, Matplotlib, Seaborn | General Concepts |
| NLP | Natural language processing | Processing and analyzing natural language data | Enables textual data mining, supports linguistic research, automates language understanding tasks | NLTK, SpaCy, Hugging Face Transformers | General Concepts |
| One-hot encoding | Categorical variable encoding | Converts categorical data into binary vectors | Handles categorical data, prevents ordinal relationships | Scikit-learn, Pandas | General Concepts |
| Cross-validation | Model validation technique | Assessing model performance | Reduces overfitting, provides reliable performance estimates | Scikit-learn | Model Evaluation and Optimization |
| Overfitting | Model performance issue | Occurs when a model learns noise | Reduces generalization, can be mitigated with regularization | Scikit-learn, TensorFlow | Model Evaluation and Optimization |
| Underfitting | Model performance issue | Occurs when a model is too simple | Leads to poor performance on training and test data, needs more complexity | Scikit-learn, TensorFlow | Model Evaluation and Optimization |
| Hyperparameter tuning | Optimization process | Improves model performance | Finds optimal parameters, enhances model accuracy | Scikit-learn, Optuna, Hyperopt | Model Evaluation and Optimization |
| ROC | Receiver operating characteristic | Evaluating classification models | Assesses performance across different thresholds, provides AUC metric | Scikit-learn, Matplotlib | Model Evaluation and Optimization |
| AUC | Area under the ROC curve | Evaluating classification models | Measures overall performance of binary classifiers | Scikit-learn, Matplotlib | Model Evaluation and Optimization |
| F1 Score | Harmonic mean of precision and recall | Evaluating classification models | Balances precision and recall, useful for imbalanced datasets | Scikit-learn | Model Evaluation and Optimization |
| Gradient descent | Optimization algorithm | Minimizes loss functions | Efficiently finds optimal model parameters | TensorFlow, PyTorch, Scikit-learn | Model Evaluation and Optimization |
| SVM | Support vector machines | Classification and regression analysis | Effective in high-dimensional spaces, robust to overfitting with appropriate kernel choice | Scikit-learn, LibSVM | Classification and Regression Models |
| KNN | K-nearest neighbors | Classification and regression | Simple and intuitive, effective with small datasets | Scikit-learn | Classification and Regression Models |
| RF | Random forest | Classification and regression | Handles large datasets, reduces overfitting | Scikit-learn | Classification and Regression Models |
| XGBoost | Extreme Gradient Boosting | Classification and regression | High performance, handles missing data well | XGBoost library | Classification and Regression Models |
| AdaBoost | Adaptive Boosting | Classification and regression | Improves accuracy, reduces bias and variance | Scikit-learn | Classification and Regression Models |
| CNN | Convolutional neural network | Image and video recognition | High accuracy in visual tasks, useful in feature extraction, adaptable to various types of image data | TensorFlow, Keras, PyTorch | Vision Models (Neural Networks) |
| Vision Transformer (ViT) | Transformer architecture for vision tasks | Image classification, segmentation | Captures long-range dependencies, highly parallelizable, effective on large datasets | Hugging Face Transformers, PyTorch, TensorFlow | Vision Models (Neural Networks), Sequence and Text Models (Neural Networks) |
| RNN | Recurrent neural network | Sequential data processing | Captures temporal dependencies, useful in time series analysis | TensorFlow, PyTorch, Keras | Sequence and Text Models (Neural Networks), Generative Models |
| LSTM | Long short-term memory | Time series prediction | Captures long-term dependencies, prevents vanishing gradient problem | TensorFlow, Keras, PyTorch | Sequence and Text Models (Neural Networks), Generative Models |
| Transformers | Model architecture | Sequence-to-sequence tasks, generative tasks | Captures long-range dependencies, highly parallelizable, versatile for various NLP tasks | Hugging Face Transformers, TensorFlow, PyTorch | Sequence and Text Models (Neural Networks), Generative Models |
| GAN | Generative adversarial network | Data generation (images, text, etc.) | Generates realistic data, useful in image synthesis and text generation | TensorFlow, PyTorch | Generative Models |
| LLMs | Large language models | Natural language understanding and generation | Handles diverse NLP tasks, pre-trained on vast corpora | Hugging Face Transformers, OpenAI GPT-3, Google BERT | Large-Scale Models, Generative Models |
| LMM | Large multimodal models | Integrates text, image, and other data types | Provides comprehensive understanding across modalities | OpenAI CLIP, Hugging Face Transformers | Large-Scale Models, Generative Models |
| Transfer learning | Pre-trained model adaptation | Leveraging existing models for new tasks | Reduces training time, improves performance on small datasets | TensorFlow, PyTorch, Keras | Advanced Techniques and Practices |
| PCA | Principal component analysis | Dimensionality reduction | Reduces dimensionality, aids in visualization of high-dimensional data, retains most variance | Scikit-learn, NumPy | Dimensionality Reduction and Clustering |
| DBSCAN | Density-based spatial clustering of applications with noise | Clustering | Identifies clusters of arbitrary shape, handles noise | Scikit-learn | Dimensionality Reduction and Clustering |
| t-SNE | t-distributed stochastic neighbor embedding | Data visualization | Reduces dimensionality for visualization, preserves local structure | Scikit-learn, Multicore-TSNE | Dimensionality Reduction and Clustering |
| Dropout | Regularization technique | Prevents overfitting in neural networks | Improves generalization, randomly drops neurons during training | TensorFlow, Keras, PyTorch | Regularization Techniques |
| LASSO | Least absolute shrinkage and selection operator | Regression analysis | Prevents overfitting, performs feature selection | Scikit-learn | Regularization Techniques, Regression |
| Ridge | Ridge regression | Regression analysis | Prevents overfitting, handles multicollinearity | Scikit-learn | Regularization Techniques, Regression |
| Elastic Net | Combination of LASSO and Ridge | Regression analysis | Combines benefits of LASSO and Ridge, robust feature selection | Scikit-learn | Regularization Techniques, Regression |

:::
