---
title: Glossary of ML Terms
author: "ML+X"
order: 8
tbl-colwidths: [5,30]
date-modified: "last-modified"
date-format: long
---

::: column-screen-inset-right

### General Concepts
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| ML | Machine learning | Study of statistical algorithms that can learn from data and generalize to unseen data | Facilitates discovery of complex patterns, enhances predictive modeling, enables large-scale data analysis | Scikit-learn, TensorFlow, PyTorch |
| EDA | Exploratory data analysis | Understanding data before modeling | Identifies patterns, detects anomalies, informs feature selection | Pandas, Matplotlib, Seaborn |
| NLP | Natural language processing | Processing and analyzing natural language data | Enables textual data mining, supports linguistic research, automates language understanding tasks | NLTK, SpaCy, Hugging Face Transformers |
| One-hot encoding | Categorical variable encoding | Converts categorical data into binary vectors | Handles categorical data, prevents ordinal relationships | Scikit-learn, Pandas |

### Model Evaluation and Optimization
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| Cross-validation | Model validation technique | Assessing model performance | Reduces overfitting, provides reliable performance estimates | Scikit-learn |
| Overfitting | Model performance issue | Occurs when a model learns noise | Reduces generalization, can be mitigated with regularization | Scikit-learn, TensorFlow |
| Underfitting | Model performance issue | Occurs when a model is too simple | Leads to poor performance on training and test data, needs more complexity | Scikit-learn, TensorFlow |
| Hyperparameter tuning | Optimization process | Improves model performance | Finds optimal parameters, enhances model accuracy | Scikit-learn, Optuna, Hyperopt |
| ROC | Receiver operating characteristic | Evaluating classification models | Assesses performance across different thresholds, provides AUC metric | Scikit-learn, Matplotlib |
| AUC | Area under the ROC curve | Evaluating classification models | Measures overall performance of binary classifiers | Scikit-learn, Matplotlib |
| F1 Score | Harmonic mean of precision and recall | Evaluating classification models | Balances precision and recall, useful for imbalanced datasets | Scikit-learn |
| Gradient descent | Optimization algorithm | Minimizes loss functions | Efficiently finds optimal model parameters | TensorFlow, PyTorch, Scikit-learn |

### Classification and Regression Models
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| SVM | Support vector machines | Classification and regression analysis | Effective in high-dimensional spaces, robust to overfitting with appropriate kernel choice | Scikit-learn, LibSVM |
| KNN | K-nearest neighbors | Classification and regression | Simple and intuitive, effective with small datasets | Scikit-learn |
| RF | Random forest | Classification and regression | Handles large datasets, reduces overfitting | Scikit-learn |
| XGBoost | Extreme Gradient Boosting | Classification and regression | High performance, handles missing data well | XGBoost library |
| AdaBoost | Adaptive Boosting | Classification and regression | Improves accuracy, reduces bias and variance | Scikit-learn |

### Neural Networks
#### Vision Models
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| CNN | Convolutional neural network | Image and video recognition | High accuracy in visual tasks, useful in feature extraction, adaptable to various types of image data | TensorFlow, Keras, PyTorch |
| Vision Transformer (ViT) | Transformer architecture for vision tasks | Image classification, segmentation | Captures long-range dependencies, highly parallelizable, effective on large datasets | Hugging Face Transformers, PyTorch, TensorFlow |

#### Sequence and Text Models
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| RNN | Recurrent neural network | Sequential data processing | Captures temporal dependencies, useful in time series analysis | TensorFlow, PyTorch, Keras |
| LSTM | Long short-term memory | Time series prediction | Captures long-term dependencies, prevents vanishing gradient problem | TensorFlow, Keras, PyTorch |
| Transformers | Model architecture | Sequence-to-sequence tasks, generative tasks | Captures long-range dependencies, highly parallelizable, versatile for various NLP tasks | Hugging Face Transformers, TensorFlow, PyTorch |

#### Generative Models
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| GAN | Generative adversarial network | Data generation (images, text, etc.) | Generates realistic data, useful in image synthesis and text generation | TensorFlow, PyTorch |
| Transformers | Model architecture | Generative tasks (e.g., text generation) | Generates high-quality text, versatile for various generative tasks | Hugging Face Transformers, TensorFlow, PyTorch |

#### Large-Scale Models
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| LLMs | Large language models | Natural language understanding and generation | Handles diverse NLP tasks, pre-trained on vast corpora | Hugging Face Transformers, OpenAI GPT-3, Google BERT |
| Large multimodal models | Models handling multiple data modalities | Integrates text, image, and other data types | Provides comprehensive understanding across modalities | OpenAI CLIP, Hugging Face Transformers |

#### Advanced Techniques and Practices
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| Transfer learning | Pre-trained model adaptation | Leveraging existing models for new tasks | Reduces training time, improves performance on small datasets | TensorFlow, PyTorch, Keras |

### Dimensionality Reduction and Clustering
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| PCA | Principal component analysis | Dimensionality reduction | Reduces dimensionality, aids in visualization of high-dimensional data, retains most variance | Scikit-learn, NumPy |
| DBSCAN | Density-based spatial clustering of applications with noise | Clustering | Identifies clusters of arbitrary shape, handles noise | Scikit-learn |
| t-SNE | t-distributed stochastic neighbor embedding | Data visualization | Reduces dimensionality for visualization, preserves local structure | Scikit-learn, Multicore-TSNE |

### Regularization Techniques
| Term | Meaning | Application | Key Benefits | Common Libraries/Tools |
|:----:|:--------|:------------|:-------------|:-----------------------|
| Dropout | Regularization technique | Prevents overfitting in neural networks | Improves generalization, randomly drops neurons during training | TensorFlow, Keras, PyTorch |
| LASSO | Least absolute shrinkage and selection operator | Regression analysis | Prevents overfitting, performs feature selection | Scikit-learn |
| Ridge | Ridge regression | Regression analysis | Prevents overfitting, handles multicollinearity | Scikit-learn |
| Elastic Net | Combination of LASSO and Ridge | Regression analysis | Combines benefits of LASSO and Ridge, robust feature selection | Scikit-learn |


:::
