---
title: "My Amazing ML Talk" # title of talk
author: "Author 1, Author 2, Author 3" # comma separated list of author(s)/presenter(s)
date: 2023-09-19 # date published/presented

# You will need to add a representative image to the ML-X-Nexus/images folder.
  
# - OPTION 1: If posting a video from YouTube, follow these instructions to use the "thumbnail" image from the video. 
  #  1) Identify the YouTube video ID: The video ID is the unique identifier for each YouTube video, usually found 
  #     after the "v=" parameter in the URL. For example, in the URL https://www.youtube.com/watch?v=dQw4w9WgXcQ, the video ID is dQw4w9WgXcQ.
  
  #  2) Construct the thumbnail URL: YouTube provides different resolutions for video thumbnails. Here are the formats for different resolutions. We'll use the maximum resolution.
  #     Maximum resolution thumbnail: https://img.youtube.com/vi/[VIDEO_ID]/maxresdefault.jpg. Replace [VIDEO_ID] with the actual video ID, removing the square brackets.
  # image: "https://img.youtube.com/vi/dQw4w9WgXcQ/maxresdefault.jpg"

image: "https://img.youtube.com/vi/[VIDEO_ID]/maxresdefault.jpg" # replace VIDEO_ID with youtube video ID. 

# - OPTION 2: If it's not a video from YouTube, you'll have to generate/acquire your own image. You could take a screenshot of the video's title slide (assuming video is public) or use genAI to create a relevant image.
  
#image: "../../../images/my_unique_image.png" # uncomment out this line if you're using a custom image. Adjust filename to your file name. Place image in the images folder in the repo.

# Leave as is
language: 
  title-block-author-plural: "Presenters"
  title-block-published: "Date"
  
# Enter a list of relevant categories/tags for this resource, including the type (talk, video, paper, etc.) topic of focus, and anything else that might be relevant. Please check out the tags which are already being used on Nexus by visiting https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/ and looking under "Categories". Avoid repeating tags with alternative spelling (e.g., use Deep Learning rather than DL since Deep Learning is already being used.). 
# Example categories below:
categories:
  - Videos # Always include
  - ML4MI # Name of talk series (e.g., ML+X, IT Prof)
  - UW-Madison # If talk is UW-Madison affiliated, include this
  - Healthcare # Domain or application area (e..g, genomics, Agriculture, Physics, Science Communication, Neurosicence, etc.)
  - Ultrasound # specific dataset/subdomain descriptor 
  # Method descriptors: You can come up with new ones that aren't already listed on Nexus if you think it is needed. Lean towards including more rather than less; reviewers can always tirm the fat. Examples:
  - Multimodal learning # Descriptor 1 (e.g., Computer vision, NLP, Tabular)
  - Deep learning # Classical ML
  - LLaVA # specific foundation models (e.g., GPT-3, ViT), if relevant
  - LMM # Decision tree, LSTM, LMM, CNN, CNN-LSTM (general model type)
  - Transfer learning # Other misc. ML topics highlighted, e.g., Contrastive learning, Dim. reduction
  
---
### About this resource
Provide a short description of the talk and why you think it may be useful to others (4-8 sentences). Example: In this talk from the Machine Learning for Medical Imaging (ML4MI) community, Anoop Mayampurath (PhD) discusses the use of electronic health record (EHR) data and machine learning to predict clinical deterioration in hospitalized children. The presentation explores how traditional methods like the Pediatric Early Warning System (PEWS) fall short and introduces a novel model, pCART, which significantly improves outcomes by enabling early and accurate detection of at-risk patients. pCART (Pediatric Cardiac Arrest Risk Tool) is a gradient boosted tree model designed to identify clinical deterioration in hospitalized children, particularly those at risk of requiring ICU transfers. Unlike traditional methods like the Pediatric Early Warning System (PEWS), which rely on static, age-dependent cutoffs and subjective assessments, pCART utilizes advanced analytics and continuous tracking to provide a more accurate and actionable risk assessment.

<!-- MARKDOWN COMMENT:  Finally, replace the URL below with your video's URL. -->. If video is not on Youtube (e.g., Kaltura instead), use the following language: "**A netID is required to view ML4MI videos**: [View YYYY-MM-DD recording](https://mediaspace.wisc.edu/media/video-URL)."

{{< video https://www.youtube.com/watch?v=W3h9s1CG35c >}}


## See also
<!-- MARKDOWN COMMENT: Please Check the existing resources on Nexus to see if any other related resources (e.g., related books/videos, blog posts commenting on the resource, alternative approaches/frameworks, etc.) should be linked below. You may also link to resources which aren't currently on the Nexus platform, if applicable. However, if you're feeling ambitious, you may wish to post those to Nexus as well!  -->
- [Related Resource 1](Link to related resource 1): Brief description of related resource 1.
- [Related Resource 2](Link to related resource 2): Brief description of related resource 2.
- [Related Resource 3](Link to related resource 3): Brief description of related resource 3
<!-- MARKDOWN COMMENT: If posting a talk from a specific seminar, link to the full seminar page on Nexus, e.g.,... -->
- [**ML4MI**](https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/Videos/ML4MI/): Explore other talks from the ML4MI group at UW-Madison. 
