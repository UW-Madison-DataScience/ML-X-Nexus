---
title: "Kornia"
author: 
  - name: Radi Akbar
    email: makbar2@wisc.edu

date: 2024-10-29 # adjust to todayâ€™s date
date-format: long
image: ../../../images/kornia-logo.png # Add a representative image for this library resource in the images folder.

categories: 
  - Libraries # always include
  - Model exploration
  - Computer vision # E.g., Computer vision, NLP, Geospatial, Data augmentation, Preprocessing
  - Deep learning
  - PyTorch # E.g., PyTorch, Tensorflow
  - Image processing

---
## About this Library

Kornia is a differentiable library that allows classical computer vision to be integrated into deep learning models. Developed by E. Riba, D. Mishkin, D. Ponsa, E. Rublee and G. Bradski and introduced in 2020, it is built on top of PyTorch to offer tools for image processing and transformer-based computer vision models (e.g., SAM, ViT, LoFTR, and RT-DETR).

#### Key features
- **Image augmentation**: Standard image augmentation functionalities such as gaussian noise, random flips, and color jiggle.
- **Feature detection**: Classical computer vision algorithms such hessian blobs, Harris corner detector, and difference of gaussians. Deep learning-based algorithms such as Dexined, KeyNet, DISK, and DeDoDe. 
- **Transformer models**: Optimized transformers-based computer vision models such as SAM, ViT, LoFTR, and RT-DETR

## Integration and compatibility
Kornia is compatible with PyTorch and any libraries built on top of PyTorch. In addition, all features from Kornia can utilize the GPU of the host machine.

- **Frameworks Supported**: PyTorch, PyTorch-Lightning, and Fastai
- **Installation Instructions**: `pip install kornia`

## Use cases
Here are some examples of how Kornia can be applied to different machine learning tasks.

- **Image preprocessing**: Apply the Shi-Tomasi cornerness function to preprocess images for 3D reconstruction.
- **Image matching**: Apply the KeyNet algorithm to match images from different perspectives/angles.

## Tutorials and resources
- **Official tutorials**: Link to several tutorials/guides on using their models: [kornia.github.io/tutorials/](https://kornia.github.io/tutorials/)

## Questions?
If you have any lingering questions about this library, please post to the [Nexus Q&A](https://github.com/UW-Madison-DataScience/ML-X-Nexus/discussions/categories/q-a) on GitHub.

## See also
- [**ML4MI Seminar**: Vision, Language, and Vision-Language Modeling in Radiology](https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/Videos/ML4MI/24-09-16_Vision-Language-and-VisionLanguage-Modeling-in-Radiology_Tyler-Bradshaw.html): In this talk from the Machine Learning for Medical Imaging (ML4MI) community, Tyler Bradshaw (PhD) discusses the historical context (e.g., CNN, VGG) leading up to the new era of multimodal learning (e.g., vision-language models), and explores how these models are currently being leveraged in the radiology field.
- [**Workshop**: Intro to Deep Learning with PyTorch](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Workshops/Intro-Deeplearning_PyTorch.html): Explore the popular PyTorch deep learning framework.
