---
title: "iNaturalist (iNat)"
author: 
  - name: Chris Endemann
    email: endemann@wisc.edu

date: 2025-04-03
date-format: long
image: "../../../images/iNaturalist-Wordmark.png"

categories: 
  - Data
  - Image data
  - Biology
  - Ecology
  - Computer vision
  - Multimodal learning
  - Benchmarking
  - Citizen science
  - CLIP
  - Zero-shot learning
---

## About this resource

[iNaturalist (iNat)](https://www.inaturalist.org/) is one of the largest community-contributed biodiversity datasets, with millions of photos of plants, animals, and fungi submitted by citizen scientists around the world. These images are accompanied by rich metadata — including time, location, and species ID — and are verified through community consensus.

The **iNat2024 (iNat24)** subset, used in benchmarks like [INQUIRE](https://inquire-benchmark.github.io/), includes over 5 million images and provides a real-world testbed for evaluating species classification, visual reasoning, and multimodal retrieval tasks.

### What makes iNat valuable for AI?

Most large-scale image datasets are curated or scraped from the internet. In contrast, iNat data reflects real-world ecological observations: images are often messy, off-center, and diverse in setting, but rich in scientific value. This makes iNat an ideal source for developing and testing robust machine learning models.

Researchers use iNat to:

- Train and evaluate models on fine-grained species classification  
- Benchmark retrieval tasks involving complex visual and contextual cues  
- Explore zero-shot generalization using CLIP or other vision-language models  
- Support conservation efforts and ecological research at scale

### Example uses

iNat images have powered major ML benchmarks and tools, including the [INQUIRE](https://uw-madison-datascience.github.io/ML-X-Nexus/Toolbox/Data/INQUIRE.html) benchmark, which uses iNat24 to evaluate retrieval models on expert-level ecological queries

### Access and attribution

iNat data is accessible through the [iNaturalist API](https://api.inaturalist.org/), the [Global Biodiversity Information Facility (GBIF)](https://www.gbif.org/), and various competition archives. Data licensing follows Creative Commons guidelines, and attribution to individual observers is required.

## See also

- [**Data:** INQUIRE Benchmark](https://uw-madison-datascience.github.io/ML-X-Nexus/Toolbox/Data/INQUIRE.html): Built on iNat24, this benchmark supports multimodal ecological retrieval tasks.
- [**Talk:** Automating Scientific Discovery](https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/Videos/Forums/mlx_2025-03-04.html): Learn how iNat data is being used to train AI systems that support ecological research.

## Questions?

If you're using iNat or want to ask about its structure or use cases, feel free to post in the [ML+X Nexus Q&A forum](https://github.com/UW-Madison-DataScience/ML-X-Nexus/discussions/categories/q-a). 
