[
  {
    "objectID": "Contributor-templates/template_learn.html",
    "href": "Contributor-templates/template_learn.html",
    "title": "Title/Topic of Resource",
    "section": "",
    "text": "Brief description of the resource, including a text embedded link in the first 1-2 sentences. Explain what the resource covers and its relevance. Mention any specific features, strengths, or weaknesses. This section should help potential users understand the value of the resource and what they can expect to learn or achieve by using it.\n\n\n\n\nPrerequisite Resource 1\nPrerequisite Resource 2"
  },
  {
    "objectID": "Contributor-templates/template_learn.html#about-this-resource",
    "href": "Contributor-templates/template_learn.html#about-this-resource",
    "title": "Title/Topic of Resource",
    "section": "",
    "text": "Brief description of the resource, including a text embedded link in the first 1-2 sentences. Explain what the resource covers and its relevance. Mention any specific features, strengths, or weaknesses. This section should help potential users understand the value of the resource and what they can expect to learn or achieve by using it.\n\n\n\n\nPrerequisite Resource 1\nPrerequisite Resource 2"
  },
  {
    "objectID": "Contributor-templates/template_learn.html#questions",
    "href": "Contributor-templates/template_learn.html#questions",
    "title": "Title/Topic of Resource",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Contributor-templates/template_learn.html#see-also",
    "href": "Contributor-templates/template_learn.html#see-also",
    "title": "Title/Topic of Resource",
    "section": "See also",
    "text": "See also\n\n\nRelated Resource 1: Brief description of related resource 1.\nRelated Resource 2: Brief description of related resource 2.\nRelated Resource 3: Brief description of related resource 3."
  },
  {
    "objectID": "Resources/Videos/Intro-git-github.html",
    "href": "Resources/Videos/Intro-git-github.html",
    "title": "Version Control with Git and GitHub (Carpentries)",
    "section": "",
    "text": "The below video (and the 7 subsequent videos in the workshop playlist) will walk you through this introductory Git workshop from the Carpentries: Version Control with Git/GitHub. Git is a free and open source version control system that has become the #1 choice for software developers both in research and industry. Unlike centralized version control systems where there is a single central repository, Git allows every user to have a full copy of the entire project history on their own machine. This distributed nature enables multiple people to work on a project simultaneously without interfering with each other’s work. Git stores the history of changes in a project, enabling users to track progress, revert to previous states, and manage branches for different features or versions of a project. GitHub is a web-based platform that uses Git for version control. It provides a collaborative environment where users can host and review code, manage projects, and build software alongside millions of other developers. GitHub also offers additional features such as issue tracking, project management tools, and continuous integration workflows.\n\n\n\nIn this lesson we use Git from the Unix Shell. Some previous experience with the shell is expected, but isn’t mandatory. For help with Unix Shell, check out the Intro to Unix Shell workshop (Carpentries).\n\n\n\n\n\nThis workshop takes rough 3-4 hours to complete."
  },
  {
    "objectID": "Resources/Videos/Intro-git-github.html#about-this-resource",
    "href": "Resources/Videos/Intro-git-github.html#about-this-resource",
    "title": "Version Control with Git and GitHub (Carpentries)",
    "section": "",
    "text": "The below video (and the 7 subsequent videos in the workshop playlist) will walk you through this introductory Git workshop from the Carpentries: Version Control with Git/GitHub. Git is a free and open source version control system that has become the #1 choice for software developers both in research and industry. Unlike centralized version control systems where there is a single central repository, Git allows every user to have a full copy of the entire project history on their own machine. This distributed nature enables multiple people to work on a project simultaneously without interfering with each other’s work. Git stores the history of changes in a project, enabling users to track progress, revert to previous states, and manage branches for different features or versions of a project. GitHub is a web-based platform that uses Git for version control. It provides a collaborative environment where users can host and review code, manage projects, and build software alongside millions of other developers. GitHub also offers additional features such as issue tracking, project management tools, and continuous integration workflows.\n\n\n\nIn this lesson we use Git from the Unix Shell. Some previous experience with the shell is expected, but isn’t mandatory. For help with Unix Shell, check out the Intro to Unix Shell workshop (Carpentries).\n\n\n\n\n\nThis workshop takes rough 3-4 hours to complete."
  },
  {
    "objectID": "Resources/Videos/Intro-git-github.html#questions",
    "href": "Resources/Videos/Intro-git-github.html#questions",
    "title": "Version Control with Git and GitHub (Carpentries)",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Videos/Intro-git-github.html#see-also",
    "href": "Resources/Videos/Intro-git-github.html#see-also",
    "title": "Version Control with Git and GitHub (Carpentries)",
    "section": "See also",
    "text": "See also\n\nGuide: Version Control with GitHub Desktop: GitHub Desktop is a graphical user interface (GUI) application that simplifies the use of Git and GitHub. It is designed for users who prefer not to use the command line interface, offering a more intuitive and visual approach to version control. With GitHub Desktop, you can easily perform common Git tasks such as committing changes, creating branches, and resolving merge conflicts, all within a user-friendly interface.\nVideo: Reproducibility Overview Lecture: If you’re curious to learn how to use Git via shell commands (or just want to become more fluent with Git), check out this YouTube playlist from the Data Science Hub!"
  },
  {
    "objectID": "Resources/Videos/index.html",
    "href": "Resources/Videos/index.html",
    "title": "Videos",
    "section": "",
    "text": "Grokking\n\n\n\nDeep learning\n\n\nEmpirical patterns\n\n\nGrokking\n\n\nVideos\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-26\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of Reproducibility Lecture\n\n\n\nReproducibility\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with Git and GitHub (Carpentries)\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nWorkshops\n\n\nCode-along\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut-of-Distribution Detection\n\n\n\nOOD detection\n\n\nTrustworthy ML\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Learn",
      "Videos"
    ]
  },
  {
    "objectID": "Resources/Videos/OOD-detection.html",
    "href": "Resources/Videos/OOD-detection.html",
    "title": "Out-of-Distribution Detection",
    "section": "",
    "text": "The below tutorial from Sharon Li, an Assistant Professor in the Department of Computer Sciences at the University of Wisconsin-Madison, introduces a pervasive problem faced by many machine learning systems deployed in the wild — out-of-distribution data.\nOut-of-distribution data, often overlooked but immensely consequential, poses a significant threat to the reliability and efficacy of machine learning models. Through Sharon’s presentation, viewers gain a comprehensive understanding of this complex phenomenon and its potential ramifications on predictive accuracy.\nCheck out the video below to learn more about this problem and the cutting-edge methods you can equip yourself with to prevent inaccurate model predictions.\n\n\nDetails, slides and videos from other talks at ICCV 2023: abursuc.github.io/many-faces-reliability/\n\n\n\n\nCheck this page again soon for worked examples and exercises (code provided)!"
  },
  {
    "objectID": "Resources/Videos/OOD-detection.html#about-this-resource",
    "href": "Resources/Videos/OOD-detection.html#about-this-resource",
    "title": "Out-of-Distribution Detection",
    "section": "",
    "text": "The below tutorial from Sharon Li, an Assistant Professor in the Department of Computer Sciences at the University of Wisconsin-Madison, introduces a pervasive problem faced by many machine learning systems deployed in the wild — out-of-distribution data.\nOut-of-distribution data, often overlooked but immensely consequential, poses a significant threat to the reliability and efficacy of machine learning models. Through Sharon’s presentation, viewers gain a comprehensive understanding of this complex phenomenon and its potential ramifications on predictive accuracy.\nCheck out the video below to learn more about this problem and the cutting-edge methods you can equip yourself with to prevent inaccurate model predictions.\n\n\nDetails, slides and videos from other talks at ICCV 2023: abursuc.github.io/many-faces-reliability/\n\n\n\n\nCheck this page again soon for worked examples and exercises (code provided)!"
  },
  {
    "objectID": "Resources/Videos/OOD-detection.html#questions",
    "href": "Resources/Videos/OOD-detection.html#questions",
    "title": "Out-of-Distribution Detection",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Workshops/Intro-TextAnalysis_Python.html",
    "href": "Resources/Workshops/Intro-TextAnalysis_Python.html",
    "title": "Intro to Text Analysis / NLP (Carpentries)",
    "section": "",
    "text": "The Intro to Text Analysis workshop introduces the field of Natural Language Processing (NLP) and how to gain insights from collections of text data (i.e., a corpus). This includes a hands-on, step-by-step guide on how to source and prepare a corpus for analysis, generate text (document/sentence/word) embeddings, perform topic modeling, deploy common models (e.g., Word2Vec and large language models using Hugging Face), and ethical considerations. Students and researchers working with text data (especially the digital humanities!) are encouraged to take this workshop!\n\n\nLearners are expected to have basic Python programming skills and familiarity with the Pandas package. If you need a refresher, the Introductory Python lesson materials are available for independent study.\n\n\n\nThis workshop takes approximately 16 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials.\n\n\n\n\nWorkshop: Intro to Deep Learning with Keras: Explore deep learning concepts in greater detail. This will help you better understand the technology (neural networks) needed for Word2Vec and large language models.\nBook: Understanding Deep Learning - Simon J.D. Prince: This free textbook is a good modern overview of deep learning (and machine learning in general), and provides colab notebooks to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice. You may find additional details in this book that the workshop only briefly touches on."
  },
  {
    "objectID": "Resources/Workshops/Intro-TextAnalysis_Python.html#about-this-resource",
    "href": "Resources/Workshops/Intro-TextAnalysis_Python.html#about-this-resource",
    "title": "Intro to Text Analysis / NLP (Carpentries)",
    "section": "",
    "text": "The Intro to Text Analysis workshop introduces the field of Natural Language Processing (NLP) and how to gain insights from collections of text data (i.e., a corpus). This includes a hands-on, step-by-step guide on how to source and prepare a corpus for analysis, generate text (document/sentence/word) embeddings, perform topic modeling, deploy common models (e.g., Word2Vec and large language models using Hugging Face), and ethical considerations. Students and researchers working with text data (especially the digital humanities!) are encouraged to take this workshop!\n\n\nLearners are expected to have basic Python programming skills and familiarity with the Pandas package. If you need a refresher, the Introductory Python lesson materials are available for independent study.\n\n\n\nThis workshop takes approximately 16 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials.\n\n\n\n\nWorkshop: Intro to Deep Learning with Keras: Explore deep learning concepts in greater detail. This will help you better understand the technology (neural networks) needed for Word2Vec and large language models.\nBook: Understanding Deep Learning - Simon J.D. Prince: This free textbook is a good modern overview of deep learning (and machine learning in general), and provides colab notebooks to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice. You may find additional details in this book that the workshop only briefly touches on."
  },
  {
    "objectID": "Resources/Workshops/Intro-Python_Gapminder.html",
    "href": "Resources/Workshops/Intro-Python_Gapminder.html",
    "title": "Intro to Python (Carpentries)",
    "section": "",
    "text": "The Plotting and Programming in Python workshop provides an introduction to programming in Python 3 for people with little or no previous programming experience. It uses plotting as its motivating example to learn Python fundamentals, including functions, conditional logic, loops, and popular packages (e.g., Pandas).\n\n\nNo previous experience with programming necessary.\n\n\n\nThis workshop takes approximately 8 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-Python_Gapminder.html#about-this-resource",
    "href": "Resources/Workshops/Intro-Python_Gapminder.html#about-this-resource",
    "title": "Intro to Python (Carpentries)",
    "section": "",
    "text": "The Plotting and Programming in Python workshop provides an introduction to programming in Python 3 for people with little or no previous programming experience. It uses plotting as its motivating example to learn Python fundamentals, including functions, conditional logic, loops, and popular packages (e.g., Pandas).\n\n\nNo previous experience with programming necessary.\n\n\n\nThis workshop takes approximately 8 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-Python_Gapminder.html#questions",
    "href": "Resources/Workshops/Intro-Python_Gapminder.html#questions",
    "title": "Intro to Python (Carpentries)",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Workshops/Intro-Python_Gapminder.html#see-also",
    "href": "Resources/Workshops/Intro-Python_Gapminder.html#see-also",
    "title": "Intro to Python (Carpentries)",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Machine Learning with Sklearn: Once you master Python fundamentals, start using the scikit-learn package to begin exploring “classical” ML methods (e.g., regression, clustering, decision trees)."
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_Keras.html",
    "href": "Resources/Workshops/Intro-Deeplearning_Keras.html",
    "title": "Intro to Deep Learning with Keras (Carpentries)",
    "section": "",
    "text": "The Intro to Deep Learning with Keras workshop from the Carpentries will walk you through introductory deep learning concepts as well as how to build a neural networks in Keras. Keras is high-level wrapper framework (uses PyTorch or Tensorflow in the backend) which allows you to train and evaluate neural networks in just a few lines of code. It may take slightly longer to train a Keras model (compared to PyTorch and Tensorflow), but the difference in performance is often negligible for those that only need to train a few models. The ability to quickly build and test models is the primary selling point of Keras.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\nBasic knowledge on machine learning, including the following concepts: Data cleaning, train & test split, type of problems (regression, classification), overfitting & underfitting, metrics (accuracy, recall, etc.).The Intro to Machine Learning with Sklearn lesson materials are a good option for those that need a refresher on machine learning fundamentals.\n\n\n\n\nThis workshop takes approximately 15 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_Keras.html#about-this-resource",
    "href": "Resources/Workshops/Intro-Deeplearning_Keras.html#about-this-resource",
    "title": "Intro to Deep Learning with Keras (Carpentries)",
    "section": "",
    "text": "The Intro to Deep Learning with Keras workshop from the Carpentries will walk you through introductory deep learning concepts as well as how to build a neural networks in Keras. Keras is high-level wrapper framework (uses PyTorch or Tensorflow in the backend) which allows you to train and evaluate neural networks in just a few lines of code. It may take slightly longer to train a Keras model (compared to PyTorch and Tensorflow), but the difference in performance is often negligible for those that only need to train a few models. The ability to quickly build and test models is the primary selling point of Keras.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\nBasic knowledge on machine learning, including the following concepts: Data cleaning, train & test split, type of problems (regression, classification), overfitting & underfitting, metrics (accuracy, recall, etc.).The Intro to Machine Learning with Sklearn lesson materials are a good option for those that need a refresher on machine learning fundamentals.\n\n\n\n\nThis workshop takes approximately 15 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_Keras.html#questions",
    "href": "Resources/Workshops/Intro-Deeplearning_Keras.html#questions",
    "title": "Intro to Deep Learning with Keras (Carpentries)",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_Keras.html#see-also",
    "href": "Resources/Workshops/Intro-Deeplearning_Keras.html#see-also",
    "title": "Intro to Deep Learning with Keras (Carpentries)",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Deep Learning with PyTorch: Explore PyTorch as an alternative deep learning framework.\nBook: Understanding Deep Learning - Simon J.D. Prince: This free textbook is a good modern overview of deep learning, and provides colab notebooks to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice. You may find additional details in this book that the workshop only briefly touches on."
  },
  {
    "objectID": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html",
    "href": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html",
    "title": "Understanding Deep Learning",
    "section": "",
    "text": "Nowadays, nearly anyone can implement a deep learning model in a just a few lines of code. What separates the novices from the experts, however, is the ability to understand (or at least predict!) how these models work in different circumstances.\nSimon J.D. Prince’s free textbook, Understanding Deep Learning, provides a modern overview of deep learning (including newer topics like double descent and transformer models), and provides colab notebooks (!!!) to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice.\n\n\nThe title of this book is “Understanding Deep Learning” to distinguish it from volumes that cover coding and other practical aspects. This text is primarily about the ideas that underlie deep learning. The first part of the book introduces deep learning models and discusses how to train them, measure their performance, and improve this performance. The next part considers architectures that are specialized to images, text, and graph data. These chapters require only introductory linear algebra, calculus, and probability and should be accessible to any second-year undergraduate in a quantitative discipline. Subsequent parts of the book tackle generative models and reinforcement learning. These chapters require more knowledge of probability and calculus and target more advanced students. The title is also partly a joke — no-one really understands deep learning at the time of writing. Modern deep networks learn piecewise linear functions with more regions than there are atoms in the universe and can be trained with fewer data examples than model parameters. It is neither obvious that we should be able to fit these functions reliably nor that they should generalize well to new data. The penultimate chapter addresses these and other aspects that are not yet fully understood. Regardless, deep learning will change the world for better or worse. The final chapter discusses AI ethics and concludes with an appeal for practitioners to consider the moral implications of their work.\n\n\nLearners are expected to have the following knowledge:\n\nLinear algebra: linear algebra is the language of machine learning\nCalculus: recommended to understand gradient descent\nProbability theory: needed for reinforcement learning\nPyTorch: recommended for following along with Colab notebooks\n\n\n\n\nTBD: Use the Improve this page functionality to add your own estimate!"
  },
  {
    "objectID": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#about-this-resource",
    "href": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#about-this-resource",
    "title": "Understanding Deep Learning",
    "section": "",
    "text": "Nowadays, nearly anyone can implement a deep learning model in a just a few lines of code. What separates the novices from the experts, however, is the ability to understand (or at least predict!) how these models work in different circumstances.\nSimon J.D. Prince’s free textbook, Understanding Deep Learning, provides a modern overview of deep learning (including newer topics like double descent and transformer models), and provides colab notebooks (!!!) to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice.\n\n\nThe title of this book is “Understanding Deep Learning” to distinguish it from volumes that cover coding and other practical aspects. This text is primarily about the ideas that underlie deep learning. The first part of the book introduces deep learning models and discusses how to train them, measure their performance, and improve this performance. The next part considers architectures that are specialized to images, text, and graph data. These chapters require only introductory linear algebra, calculus, and probability and should be accessible to any second-year undergraduate in a quantitative discipline. Subsequent parts of the book tackle generative models and reinforcement learning. These chapters require more knowledge of probability and calculus and target more advanced students. The title is also partly a joke — no-one really understands deep learning at the time of writing. Modern deep networks learn piecewise linear functions with more regions than there are atoms in the universe and can be trained with fewer data examples than model parameters. It is neither obvious that we should be able to fit these functions reliably nor that they should generalize well to new data. The penultimate chapter addresses these and other aspects that are not yet fully understood. Regardless, deep learning will change the world for better or worse. The final chapter discusses AI ethics and concludes with an appeal for practitioners to consider the moral implications of their work.\n\n\nLearners are expected to have the following knowledge:\n\nLinear algebra: linear algebra is the language of machine learning\nCalculus: recommended to understand gradient descent\nProbability theory: needed for reinforcement learning\nPyTorch: recommended for following along with Colab notebooks\n\n\n\n\nTBD: Use the Improve this page functionality to add your own estimate!"
  },
  {
    "objectID": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#questions",
    "href": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#questions",
    "title": "Understanding Deep Learning",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#see-also",
    "href": "Resources/Books/Intro-Deeplearning_SimonJDPrince.html#see-also",
    "title": "Understanding Deep Learning",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Deep Learning with PyTorch: Explore PyTorch as an alternative deep learning framework.\nWorkshop: Intro to Deep Learning with Keras: Explore Keras as an alternative deep learning framework"
  },
  {
    "objectID": "Resources/Guides/index.html",
    "href": "Resources/Guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "Version Control with GitHub Desktop\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nGuides\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCenter for Highthroughput Computing (CHTC)\n\n\n\nCompute\n\n\nGPU\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-06-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Contribute?\n\n\n\nContribute\n\n\nGuides\n\n\n\n\n\n\n\nML+X\n\n\n2024-06-24\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Learn",
      "Guides"
    ]
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html",
    "href": "Resources/Guides/Github-desktop.html",
    "title": "Version Control with GitHub Desktop",
    "section": "",
    "text": "Navigating the world of version control systems like Git can initially feel daunting, especially for those new to programming or collaborative software development projects. However, with the right tools and guidance, anyone can quickly grasp the essentials and begin leveraging the power of Git for efficient project management and collaboration. While Git commands can be run via a Unix shell, there are alternatives which are more friendly for beginners. In this guide, we’ll explore GitHub Desktop as a convenient and accessible gateway to Git, along with a step-by-step walkthrough on essential Git terminology, setup procedures, tracking changes, collaboration workflows, and even managing Kaggle notebooks seamlessly. Whether you’re embarking on your first coding adventure or seeking to streamline your team’s development process, this guide aims to demystify Git and empower you with practical knowledge to navigate the Git landscape with confidence."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#about-this-resource",
    "href": "Resources/Guides/Github-desktop.html#about-this-resource",
    "title": "Version Control with GitHub Desktop",
    "section": "",
    "text": "Navigating the world of version control systems like Git can initially feel daunting, especially for those new to programming or collaborative software development projects. However, with the right tools and guidance, anyone can quickly grasp the essentials and begin leveraging the power of Git for efficient project management and collaboration. While Git commands can be run via a Unix shell, there are alternatives which are more friendly for beginners. In this guide, we’ll explore GitHub Desktop as a convenient and accessible gateway to Git, along with a step-by-step walkthrough on essential Git terminology, setup procedures, tracking changes, collaboration workflows, and even managing Kaggle notebooks seamlessly. Whether you’re embarking on your first coding adventure or seeking to streamline your team’s development process, this guide aims to demystify Git and empower you with practical knowledge to navigate the Git landscape with confidence."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#getting-started",
    "href": "Resources/Guides/Github-desktop.html#getting-started",
    "title": "Version Control with GitHub Desktop",
    "section": "Getting Started",
    "text": "Getting Started\n\nVersion Control\nVersion control is system that records changes to a file or set of files over time so that you can recall specific versions later. It helps in managing changes, keeping track of different versions, and collaborating with multiple people. Version control is an essential tool for reproducible science and software systems that can improve over time.\n\n\nGit\nGit is a free and open source version control system that has become the #1 choice for software developers both in research and industry. Unlike centralized version control systems where there is a single central repository, Git allows every user to have a full copy of the entire project history on their own machine. This distributed nature enables multiple people to work on a project simultaneously without interfering with each other’s work. Git stores the history of changes in a project, enabling users to track progress, revert to previous states, and manage branches for different features or versions of a project.\n\n\nGitHub\nGitHub is a web-based platform that uses Git for version control. It provides a collaborative environment where users can host and review code, manage projects, and build software alongside millions of other developers. GitHub also offers additional features such as issue tracking, project management tools, and continuous integration workflows.\n\n\nGitHub Desktop\nGitHub Desktop is a graphical user interface (GUI) application that simplifies the use of Git and GitHub. It is designed for users who prefer not to use the command line interface, offering a more intuitive and visual approach to version control. With GitHub Desktop, you can easily perform common Git tasks such as committing changes, creating branches, and resolving merge conflicts, all within a user-friendly interface.\n\n\nEssential Terminology\nBecoming familiar with version control terminology is half the battle in becoming fluent in Git/GitHub. Study the terms below to become better acquainted and revisit as needed. We’ll refer to these terms often throughout this guide.\n\nRepository == repo: A project that is tracked via git/GitHub\n\nRemote repo: A git project that is stored on GitHub\nLocal repo: A git project that has been downloaded to your local machine\n\nClone: Cloning is the process of making a copy of a remote repo on your local machine. This allows you to work on the project locally and perform tasks like commits, branches, and pulls.\nCommit: A git command that marks the completion of new work to a repo (e.g., add a new script, add a feature, fill out README). You can always recover previous versions of your work by loading up a previous commit.\nPush: A git command that sends local changes (commits) stored in your local repo to the remote repo.\nPull: A git command that allows you to update your local repo based on changes made to the remote repo (e.g., if your colleague pushes to the remote repo)\nBranch: A branch in Git is a parallel line of development that allows you to work on features, bug fixes, or experiments without affecting the main codebase. You can create and switch between branches to isolate your work.\nMerge: Merging is the process of integrating changes from one branch into another. This is typically done to combine the changes made in a** feature branch** with the main branch (e.g., main or master).\nPull Request (PR): A pull request is a feature provided by platforms like GitHub, GitLab, and Bitbucket. It’s a way to propose changes (commits) to a project. Others can review the changes, and once approved, they can be merged into the main branch.\nFork: Forking a repository means creating a copy of someone else’s project in your GitHub account. This allows you to make changes independently and propose those changes back to the original project via pull requests. If everyone on your team has write-access to the repo, it’s best to use new branches instead of forks for pull requests.\nGitignore: A .gitignore file is used to specify which files and directories should be excluded from version control. It’s essential for preventing unnecessary or sensitive files (contains like API keys) from being included in the repository."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#setup",
    "href": "Resources/Guides/Github-desktop.html#setup",
    "title": "Version Control with GitHub Desktop",
    "section": "Setup",
    "text": "Setup\nIn this section, we will walk you through setting up a GitHub repository for a collaborative software project. As an example case, imagine you and your team are preparing for a Kaggle competition and need a streamlined way to manage your code, track changes, and collaborate efficiently. By following the steps below, you’ll learn how to create a new repository, add collaborators, set up secure access, and clone the repository to your local machine, ensuring everyone on your team is ready to contribute seamlessly.\n\nInstall GitHub Desktop\n\nVisit https://desktop.github.com/ to install\n\nCreate repo\n\nVisit https://github.com/ and sign in to your GitHub account (or create an account)\nClick the green “new” button to create a new repo\nProvide a name for the project, e.g., “my_kaggle_project”\nGive a description: “Git repo for collaborating on Kaggle project for MLM23.”\nSet to private if you’re worried about having your work scooped. Otherwise set to public.\nAdd a README file: best practice is to include a README file that explains how to use your code/repo\nChoose a license: https://choosealicense.com/. MIT license is usually best for open-source projects.\n\nAdd collaborator(s)\n\nFrom your repo homepage on GitHub, click the settings tab\nClick on the “Collaborators” menu option shown in the left panel\nClick “Add people” and enter your collaborator’s username or GitHub email address\n\nSetup SSH key: SSH provides a secure way to authenticate and transfer data between your local machine and GitHub. You can also use HTTPS if you prefer, but it is less secure. HTTPS avoids having to generate an SSH key, but you will need to enter your GitHub login credentials from time to time.\n\nOpen GitBash (windows) or terminal (Mac) and run the following commands replacing the example email with your GitHub email:\n\nssh-keygen -t ed25519 -C “your_github_email@address.com”\ncat ~/.ssh/id_ed25519.pub\nThe ssh-keygen produces private and public keys, and make sure to copy and paste the output from the command\ncat ~/.ssh/id_ed25519.pub\n\nPaste output (starts like ssh-ed25519) into the new SSH key under GitHub settings (SSH and GPG Keys) and save the key\n\nClone repo\n\nFrom your GitHub repo homepage, click the green “Code” button\nSelect SSH if you setup an SSH key or select HTTPS if you don’t have one setup. Copy the URL shown.\nOpen GitHub Desktop\nClick File → Clone repository → URL\nPaste the repo URL and pay attention to the destination folder path so you can access this folder later\nClick “Clone”"
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#tracking-changes",
    "href": "Resources/Guides/Github-desktop.html#tracking-changes",
    "title": "Version Control with GitHub Desktop",
    "section": "Tracking changes",
    "text": "Tracking changes\nNow that you have set up your collaborative Kaggle hackathon repository, it’s time to start working on your project and track the changes you make. In this section, we will guide you through the process of adding files to your local repository, viewing and committing changes, and pushing those changes to the remote repository on GitHub. By understanding how to track changes effectively, you and your team can ensure that all contributions are recorded, reviewed, and integrated smoothly into the project.\n\nAdd a blank text file to your local repo\n\nRight-click repo name in GitHub Desktop → show in explorer (show in Finder and go to the directory on Mac)\nCreate a new text file and add to local repo folder\nAdd a line of text to the file, e.g., “hello world” and save the file\n\nView local changes\n\nIn GitHub desktop, you can view this change under the “Changes” tab. Notice that we see the new file and added text under this tab.\n\nCommit the new file\n\nCommits mark a checkpoint in the progress you have made to your repo. Provide a short summary message and optionally provide more information in the “Description” box.\n\nView remote changes (or lack thereof)\n\nVisit GitHub and notice that the change is not yet reflected on GitHub\n\nPush the change to GitHub \nView remote changes\n\nVisit GitHub again and notice the change has now been transferred to GitHub. Your collaborators can now access your changes through the remote repo (the repo stored on GitHub)"
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#ignoring-.ipynb-files",
    "href": "Resources/Guides/Github-desktop.html#ignoring-.ipynb-files",
    "title": "Version Control with GitHub Desktop",
    "section": "Ignoring .ipynb files",
    "text": "Ignoring .ipynb files\nAs you collaborate on your Kaggle hackathon project, you may encounter challenges with tracking changes in Jupyter notebooks (.ipynb files) due to their complex JSON format. These files can include a lot of metadata that makes version control difficult and cluttered. In this section, we’ll show you how to use Jupytext to convert your Jupyter notebooks into a more manageable format and configure your repository to ignore .ipynb files. This approach will help you maintain a cleaner version history and focus on the actual code changes, making collaboration more efficient.\n\nAdd jupyter lab file to repo\n\nOpen anaconda prompt and cd into your local repo folder\nrun “jupyter lab” command to start a new jupyter lab instance\ncreate a new notebook, e.g., preprocess_data.ipynb\nadd a line of code, e.g., print(‘hello world’)\nsave the notebook and open GitHub desktop\n\nIn GitHub desktop, notice the changes being tracked are wildly confusing. \n\nJupyter files are stored in JSON format which includes a lot of metadata unrelated to the changes you made to your file. The solution? Use Jupytext!\n\nInstall jupytext\n\npip install jupytext\njupytext –set-formats ipynb,py *.ipynb # convert .ipynb files to .py\njupytext –set-formats py,ipynb *.py\n\nalternatively to convert just one specific file: jupytext –set-formats ipynb,py file_name.ipynb\n\n\ngit ignore .ipynb files\n\nright click one of the .ipynb files in GitHub Desktop\nignore all files of this type\n\ncommit changes\npush and view changes on GitHub"
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#pulling-updates-from-github",
    "href": "Resources/Guides/Github-desktop.html#pulling-updates-from-github",
    "title": "Version Control with GitHub Desktop",
    "section": "Pulling updates from GitHub",
    "text": "Pulling updates from GitHub\nAs your team collaborates on the Kaggle hackathon project, it’s essential to stay up-to-date with the latest changes made by your teammates. In this section, we’ll explain how to pull updates from the remote repository on GitHub to your local machine. This process ensures that you always have the most recent version of the project and can integrate your work with the contributions of others seamlessly. By regularly pulling updates, you can avoid conflicts and ensure smooth collaboration throughout the project.\n\nPretend you are a collaborator and visit GitHub to find your repo\nAdd a new file to the remote repo (the version stored on GitHub): Add file → create new file.\nCommit the file to the repo\nOpen your local repo folder and notice we don’t have this new file yet\nIn GitHub Desktop, click “Fetch origin” by “Pull origin”\n\nFetch origin will run and inform you of any changes made to the remote copy of the repo (the one stored on GitHub)\nIf changes have been made since you last pulled, you’ll see the Fetch button turn into a “Pull” option. Click this option to retrieve any updates from GitHub and pull them into the local version of your repo.\n\nCheck your local repo folder to verify the new file has been pulled from GitHub onto your machine"
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#reverting-to-a-previous-commit",
    "href": "Resources/Guides/Github-desktop.html#reverting-to-a-previous-commit",
    "title": "Version Control with GitHub Desktop",
    "section": "Reverting to a previous commit",
    "text": "Reverting to a previous commit\nDuring the course of your Kaggle hackathon project, there may be times when you need to revert to a previous version of your code. This could be due to a bug, an unwanted change, or simply the need to return to a stable state. In this section, we’ll guide you through the process of reverting to a previous commit using GitHub Desktop. Understanding how to revert to an earlier commit ensures that you can quickly and safely undo changes, helping your team maintain a stable and functional codebase throughout the competition.\n\nFind the Commit to Revert To\n\nOpen GitHub Desktop and navigate to the repository you are working on.\nClick on the “History” tab to view the commit history of your repository.\nScroll through the list of commits and locate the commit you want to revert to. Click on the specific commit to select it.\n\nCreate a New Branch from the Selected Commit\n\nWith the desired commit selected, click on the “Branch” menu at the top of GitHub Desktop.\nSelect “New Branch” from the dropdown menu.\nIn the dialog box that appears, name your new branch (e.g., “revert-to-commit”) and ensure that it is based on the selected commit. Click “Create Branch” to proceed.\n\nMake Necessary Changes in the New Branch\n\nSwitch to the newly created branch by clicking on the “Current Branch” dropdown menu and selecting your new branch.\nMake any necessary changes in this branch to resolve issues or implement desired modifications.\nUse your code editor or IDE to make and save these changes.\n\nCommit the Changes to the New Branch\n\nReturn to GitHub Desktop and navigate to the “Changes” tab.\nReview the changes you made and provide a commit message summarizing them.\nClick the “Commit to ” button to commit these changes to the new branch.\n\nPush the Changes to GitHub\n\nClick the “Publish branch” button in GitHub Desktop to push your changes to the remote repository on GitHub.\nWait for the push process to complete.\n\nCreate a Pull Request (Optional)\n\nIf you want to merge these changes back into the main branch, go to your repository on GitHub.\nClick on the “Pull requests” tab and then click the “New pull request” button.\nSelect your new branch as the source and the main branch as the destination. Review the changes and click “Create pull request.”\n\nReview and Merge (If Using a Pull Request)\n\nReviewers can now examine the pull request on GitHub. They can leave comments, request changes, or approve the pull request.\nOnce the changes are approved, the pull request can be merged into the main branch by clicking the “Merge pull request” button on GitHub."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#using-pull-requests-to-review-each-others-work",
    "href": "Resources/Guides/Github-desktop.html#using-pull-requests-to-review-each-others-work",
    "title": "Version Control with GitHub Desktop",
    "section": "Using “pull requests” to review each other’s’ work",
    "text": "Using “pull requests” to review each other’s’ work\nPull requests are an essential feature of GitHub that facilitate collaborative development by allowing team members to propose changes to a codebase. They provide a structured way for team members to review, discuss, and approve changes before they are merged into the main branch. In this section, we will explore how to use pull requests effectively to ensure that your team’s work is consistently high-quality and integrated smoothly. By following best practices for creating, reviewing, and merging pull requests, you can maintain a clean and stable codebase while fostering a collaborative and transparent development process. These instructions are clear and structured well, but a few refinements can enhance clarity and flow. Here’s an improved version:\n\nCreate a New Branch:\n\nOpen GitHub Desktop and select your repository.\nClick the “Current Branch” dropdown.\nSelect “New Branch” and give it a descriptive name (e.g., “feature-branch” or “collaborator-feature”).\nChoose the base branch, typically the default branch like main or master, and click “Create Branch.”\n\nMake Changes in the New Branch:\n\nSwitch to the newly created branch by selecting it from the “Current Branch” dropdown.\nCollaborators can now make changes in this new branch. They can create, edit, or delete files as needed.\n\nCommit and Push Changes:\n\nAfter making changes, go to the “Changes” tab in GitHub Desktop.\nReview the changes, provide a meaningful commit message, and click “Commit to ”.\nClick “Push origin” to push the changes to the remote repository on GitHub.\n\nPreview Pull Request:\n\nIn GitHub Desktop, click on “Branch” in the menu bar.\nSelect “Create Pull Request” to open a preview. This will show which branch is being merged into the main code base.\n\nCreate Pull Request:\n\nAfter confirming that the preview is correct, click “Create Pull Request”.\nGitHub will open in your web browser. Fill out the details for the pull request, including a title and description.\nAssign reviewers (e.g., you and other collaborators) to review the changes, then click “Create Pull Request.”\n\nReview and Submit the Pull Request on GitHub:\n\nCollaborators should review the pull request on the GitHub website.\nThey can add comments, suggestions, or request changes directly in the pull request interface.\n\nReview the Pull Request in GitHub Desktop:\n\nReturn to GitHub Desktop to see the newly created pull request listed in the “Current Branch” dropdown.\nClick on the pull request to view the changes, comments, and review the code.\nRespond to any feedback or comments in the GitHub Desktop interface.\n\nAccept or Request Changes:\n\nAfter reviewing the code, you and other collaborators can either accept the pull request if it’s ready to merge or request changes if there are issues to address.\nLeave comments, suggestions, and feedback in the pull request.\n\nCollaborators Make Changes:\n\nIf changes are requested, collaborators can make the necessary adjustments in their branch and push the updates.\nThe pull request will automatically update with the new commits.\n\nClose the Pull Request:\n\nOnce the pull request is approved and the changes have been successfully reviewed, merge the pull request into the main branch.\nAfter merging, you can delete the branch to keep the repository clean."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#questions",
    "href": "Resources/Guides/Github-desktop.html#questions",
    "title": "Version Control with GitHub Desktop",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Guides/Github-desktop.html#see-also",
    "href": "Resources/Guides/Github-desktop.html#see-also",
    "title": "Version Control with GitHub Desktop",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Version Control with Git: If you’re curious to learn how to use Git via shell commands (or just want to become more fluent with Git), check out this YouTube playlist from the Data Science Hub!\nVideo: Reproducibility Overview Lecture: If you’re curious to learn how to use Git via shell commands (or just want to become more fluent with Git), check out this YouTube playlist from the Data Science Hub!"
  },
  {
    "objectID": "In-progress/pretrained-models.html",
    "href": "In-progress/pretrained-models.html",
    "title": "Pretrained models",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "Applications/Highlights/index.html",
    "href": "Applications/Highlights/index.html",
    "title": "Highlights",
    "section": "",
    "text": "Discover a curated collection of talks which dive into ML applications and lessons learned by practitioners.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Healthcare and Agriculture through Computer Vision\n\n\n\n\n\n\nForums\n\n\nComputer vision\n\n\nUltrasound\n\n\nAgriculture\n\n\nLSTM\n\n\nCNN-LSTM\n\n\nCNN\n\n\nDeep learning\n\n\n\n1. An ultrasound-based method to measure knee kinematics enabled by deep learning 2. Plant breeding in the age of computer vision \n\n\n\n\n\n2024-04-09\n\n\nMatthew Blomquist, Will de la Bretonne\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Model Sharing in the Age of Foundation Models\n\n\n\n\n\n\nForums\n\n\nMultimodal learning\n\n\nFoundation models\n\n\nModel sharing\n\n\nHugging Face\n\n\nLLM\n\n\nLMM\n\n\nLLaVA\n\n\nDeep learning\n\n\n\n1. Model sharing and reproducible ML 2. LLaVA-NeXT and model sharing \n\n\n\n\n\n2024-03-12\n\n\nChris Endemann, Haotian Liu\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Gravitational Waves with AI Insights\n\n\n\n\n\n\nForums\n\n\nPhysics\n\n\nSimulations\n\n\n\n1. Welcome and small group discussions 2. Classifying gravitational wave modes from core-collapse supernovae \n\n\n\n\n\n2024-02-13\n\n\nChris Endemann, Bella Finkel\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Science Communication and Drug Synergy Analysis using GPT\n\n\n\n\n\n\nForums\n\n\nScience communication\n\n\nHealthcare\n\n\nDrug synergy\n\n\nLLM\n\n\nText mining\n\n\n\n1. GPT for Science Communication: User-Interface and Developer Pipeline Approaches 2. Advancing Biomedical Research with GPT-4: A Novel Approach to Drug Synergy Analysis using Text Mining and Classification \n\n\n\n\n\n2023-12-12\n\n\nBen Rush, Jack Freeman\n\n\n\n\n\n\n\n\n\n\n\n\nLLMS in Genomic and Health Coaching\n\n\n\n\n\n\nForums\n\n\nHealthcare\n\n\nClustering\n\n\nDeep learning\n\n\nLLM\n\n\nGenomics\n\n\n\n1. Clustering of genomic sequences of mycoviruses using deep learning 2. Spurring self-improvement and intrinsic motivation using LLMs and reinforcement learning \n\n\n\n\n\n2023-11-07\n\n\nRohan Sontahlia, Michael Roytman\n\n\n\n\n\n\n\n\n\n\n\n\nTime-Series Analysis\n\n\n\n\n\n\nForums\n\n\nTime-series\n\n\nGenomics\n\n\nHealthcare\n\n\n\n1. Computational Methods for Comparative Time Clocks in Early Development and Tissue Regeneration 2. Controlled Differential Equations on Long Sequences via Non-standard Wavelets \n\n\n\n\n\n2023-10-10\n\n\nPeng Jiang, Sourav Pal\n\n\n\n\n\n\n\n\n\n\n\n\nMultimodal Learning\n\n\n\n\n\n\nForums\n\n\nMultimodal learning\n\n\nDeep learning\n\n\nComputer vision\n\n\nHealthcare\n\n\nGenomics\n\n\n\n1. Multimodal learning and analysis for understanding single-cell functional genomics in brains and brain diseases 2. Transforming healthcare: AI-enhanced disease quantification with vision-language models 3. The benefits of early fusion: deeply integrated audio-visual representation learning \n\n\n\n\n\n2023-09-19\n\n\nDaifeng Wang, Zachary Huemann, Pedro Morgado\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Applications",
      "Highlights"
    ]
  },
  {
    "objectID": "Applications/Highlights/Forums/index.html",
    "href": "Applications/Highlights/Forums/index.html",
    "title": "ML+X Forums",
    "section": "",
    "text": "Explore our library of ML+X forum recordings below! Each monthly ML+X forum highlights two ML applications that share a theme followed by communal discussions and project feedback.",
    "crumbs": [
      "Applications",
      "Highlights",
      "Forums"
    ]
  },
  {
    "objectID": "Applications/Highlights/Forums/index.html#join-the-next-live-forum",
    "href": "Applications/Highlights/Forums/index.html#join-the-next-live-forum",
    "title": "ML+X Forums",
    "section": "Join the next live forum!",
    "text": "Join the next live forum!\n\nWhere: Orchard View Room (rm. 3280), Discovery Building & via Zoom.\nWhen: Typically monthly on Tuesdays, 12-1pm CT. Join the Google group to receive a calendar invite (with Zoom link) and other updates. Please email us if you have any trouble joining.\n\n\nShare Your Work!\nWe encourage anyone who is using ML in their work to present at one of the ML+X forums. If interested, please fill out this brief presenter sign-up form.",
    "crumbs": [
      "Applications",
      "Highlights",
      "Forums"
    ]
  },
  {
    "objectID": "Applications/Playlists/ML-X-Forum.html",
    "href": "Applications/Playlists/ML-X-Forum.html",
    "title": "ML+X Forum",
    "section": "",
    "text": "Hosted by the ML+X community, this monthly forum event highlights two machine learning (ML) applications that share a theme (e.g., computer vision, time-series analysis, generative models, LLMs, bias and ethics, etc.) followed by communal discussions and project feedback. Whether you’re a beginner or seasoned expert in ML, participating in the ML+X forum can help you stay informed on:\n\nbest practices and limitations of ML\nrecent developments in ML including new models, tools, and theory\nmethods to efficiently deploy & maintain ML systems (“MLOps”)\nethical considerations of ML and impact on society\n\nThe Nexus platform maintains a full playlist of past forums found under Highlights."
  },
  {
    "objectID": "Applications/Playlists/ML-X-Forum.html#about-this-resource",
    "href": "Applications/Playlists/ML-X-Forum.html#about-this-resource",
    "title": "ML+X Forum",
    "section": "",
    "text": "Hosted by the ML+X community, this monthly forum event highlights two machine learning (ML) applications that share a theme (e.g., computer vision, time-series analysis, generative models, LLMs, bias and ethics, etc.) followed by communal discussions and project feedback. Whether you’re a beginner or seasoned expert in ML, participating in the ML+X forum can help you stay informed on:\n\nbest practices and limitations of ML\nrecent developments in ML including new models, tools, and theory\nmethods to efficiently deploy & maintain ML systems (“MLOps”)\nethical considerations of ML and impact on society\n\nThe Nexus platform maintains a full playlist of past forums found under Highlights."
  },
  {
    "objectID": "Applications/Playlists/ML-X-Forum.html#join-the-next-live-forum",
    "href": "Applications/Playlists/ML-X-Forum.html#join-the-next-live-forum",
    "title": "ML+X Forum",
    "section": "Join the next live forum!",
    "text": "Join the next live forum!\n\nWhere: Orchard View Room (rm. 3280), Discovery Building & via Zoom.\nWhen: Typically monthly on Tuesdays, 12-1pm CT. Join the Google group to receive a calendar invite (with Zoom link) and other updates. Please email us if you have any trouble joining."
  },
  {
    "objectID": "Applications/Playlists/ML-X-Forum.html#share-your-work",
    "href": "Applications/Playlists/ML-X-Forum.html#share-your-work",
    "title": "ML+X Forum",
    "section": "Share Your Work!",
    "text": "Share Your Work!\nWe encourage anyone who is using ML in their work to present at one of the ML+X forums. If interested, please fill out this brief presenter sign-up form."
  },
  {
    "objectID": "Applications/Playlists/ML-X-Forum.html#questions",
    "href": "Applications/Playlists/ML-X-Forum.html#questions",
    "title": "ML+X Forum",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Applications/EDA-examples/index.html",
    "href": "Applications/EDA-examples/index.html",
    "title": "Exploratory analysis",
    "section": "",
    "text": "Share your EDA methods!\nAre you passionate about data and keen to share your insights? We invite you to contribute to our exploratory data analysis (EDA) case studies on Nexus.\nWhether you’re working with biological data, engineering datasets, social sciences information, or any other domain, your contributions can help elevate the community’s understanding and application of EDA techniques.\nGet started by posting a brief summary of your EDA case study idea as an Issue on GitHub! The Nexus development team will follow up with feedback and further instructions.\n\n\nComing soon! Explore EDA case studies\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Applications",
      "EDA"
    ]
  },
  {
    "objectID": "Applications/Blogs/index.html",
    "href": "Applications/Blogs/index.html",
    "title": "Blogs",
    "section": "",
    "text": "Share your ML story!\nAre you currently immersed in an exciting ML project? We want to hear about it! Share your insights, challenges, and successes by contributing a blog post to Nexus, the ML+X resource sharing platform.\nWhether you’re exploring ML applications in biology, engineering, social sciences, or any other field, your unique perspective is invaluable. Showcase your innovation, research, and creativity to inspire others in the ML+X community.\nGet started by posting a brief summary of your blog idea as an Issue on GitHub! The Nexus development team will follow-up with feedback and further instructions.\n\n\nComing soon! Explore ML stories\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Applications",
      "Blogs"
    ]
  },
  {
    "objectID": "includes/common-resources-text.html",
    "href": "includes/common-resources-text.html",
    "title": "Nexus: Crowdsourced ML Resources",
    "section": "",
    "text": "Any content (original or external) that can help make the practice of ML more connected, accessible, efficient, and reproducible is welcome on the Nexus platform! This includes, but is not limited to:\n\n🧠 Educational materials: Explore a library of educational materials (workshops, guides, books, videos, etc.) covering a wide range of ML-related topics, tools, and workflows, from foundational concepts to advanced techniques. These materials offer clear explanations, practical examples, and actionable insights to help you navigate the complexities of ML with confidence.\n🧬 Applications & stories: Discover a curated collection of blogs, papers, and talks which dive into real-world ML applications and lessons learned by practitioners. This section also includes exploratory data analysis (EDA) case studies, which demonstrate the technical and domain knowledge needed to explore data from various fields.\n🛠 Coming soon! Models, code, & data: Learn about popular pretrained & foundation models, useful scripts, and datasets that you can leverage for your next ML project. Learn about their features, how to use them effectively, and see examples of them in action."
  },
  {
    "objectID": "Local-events/Workshops/index.html",
    "href": "Local-events/Workshops/index.html",
    "title": "Local Workshops",
    "section": "",
    "text": "Please see below for workshops taught locally at UW-Madison. To stay up-to-date on any new workshop offerings, we recommend subscribing to the Data Science @ UW newsletter.\nMost workshops listed have open source lesson materials which you are encouraged to independently study. If you are involved with a research lab on campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          offered\n        \n     \n  \n\n\n\n    \n        \n            \n                Intro to High-Dimensional Data Analysis\n                \n                    \n                    ML\n                    \n                    Regression\n                    \n                    High-Dimensional\n                    \n                \n                \n            \n                \n                    Organized by Data Science Hub, UW-Madison Carpentries\n                \n                \n                    Offered October 2024 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n                    12-16 hours to complete\n                \n            \n            \n            \n                Languages and Tools:\n                \n                Python\n                \n                Jupyter\n                \n            \n            \n            \n            \n                Packages and Libraries:\n                \n                sklearn\n                \n                pandas\n                \n                statsmodels\n                \n            \n            \n        \n        \n        \n            \n                Prerequisites\n                Introductory Python programming skills (variable assignments, how to create a function, for loops, etc.) and\nfamiliarity with the Pandas package.\nIf you need a refresher on Python before taking this workshop,\nplease review the lesson materials from this\n[Introductory Python Carpentries](https://swcarpentry.github.io/python-novice-inflammation/index.html) workshop.  \n\nFamiliarity with basic machine learning concepts including train/test splits and overfitting.\nFor a refresher on machine learning basics, please review the lesson materials from\nthe [Intro to Machine Learning with Sklearn](https://carpentries-incubator.github.io/machine-learning-novice-sklearn/)\nworkshop.\n\n            \n        \n        \n    \n        \n            \n                Intro to Deep Learning with Keras\n                \n                    \n                    ML\n                    \n                    Deep Learning\n                    \n                    Keras\n                    \n                \n                \n            \n                \n                    Organized by Data Science Hub, UW-Madison Carpentries\n                \n                \n                    Offered May 2024 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n                    12 hours to complete\n                \n            \n            \n            \n                Languages and Tools:\n                \n                Python\n                \n                Jupyter\n                \n            \n            \n            \n            \n                Packages and Libraries:\n                \n                keras\n                \n            \n            \n        \n        \n        \n            \n                Prerequisites\n                Basic Python programming skills and familiarity with the Pandas package. \n\nBasic knowledge on Machine learning, including the following concepts:\nData cleaning, train & test split, type of problems (regression, classification), overfitting & underfitting, metrics (accuracy, recall, etc.).\n\n            \n        \n        \n    \n        \n            \n                Intro to Text Analysis / Natural Language Processing\n                \n                    \n                    ML\n                    \n                    Deep Learning\n                    \n                    Large Language Models\n                    \n                    Text Embedding\n                    \n                    NLP\n                    \n                    Topic Modeling\n                    \n                \n                \n            \n                \n                    Organized by Data Science Hub, UW-Madison Carpentries\n                \n                \n                    Offered April 2024 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n                    16 hours to complete\n                \n            \n            \n            \n                Languages and Tools:\n                \n                Python\n                \n                Jupyter\n                \n            \n            \n            \n            \n                Packages and Libraries:\n                \n                gensim\n                \n                transformers\n                \n                sklearn\n                \n                pandas\n                \n            \n            \n        \n        \n        \n            \n                Prerequisites\n                Basic Python programming skills and familiarity with the Pandas package. \n\n            \n        \n        \n    \n        \n            \n                How to Analyze Data Using Python\n                \n                    \n                \n                \n            \n                \n                \n                    Offered March 2024 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n            \n            \n            \n        \n        \n    \n        \n            \n                How to Analyze Data Using R\n                \n                    \n                \n                \n            \n                \n                \n                    Offered March 2024 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n            \n            \n            \n        \n        \n    \n        \n            \n                Intro to Machine Learning with Scikit Learn\n                \n                    \n                    ML\n                    \n                \n                \n            \n                \n                    Organized by Data Science Hub, UW-Madison Carpentries\n                \n                \n                    Offered September 2023 |\n                \n                    \n                        Lesson Materials\n                     |\n                    \n                        Registration\n                    \n                \n                    8 hours to complete\n                \n            \n            \n            \n                Languages and Tools:\n                \n                Python\n                \n                Jupyter\n                \n            \n            \n            \n            \n                Packages and Libraries:\n                \n                sklearn\n                \n                pandas\n                \n            \n            \n        \n        \n        \n            \n                Prerequisites\n                A basic understanding of Python. You will need to know how to write a for loop, if statement, use functions, libraries and perform basic arithmetic. Either of the Software Carpentry Python courses cover sufficient background (e.g., https://swcarpentry.github.io/python-novice-inflammation/index.html)\n\n            \n        \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary of ML Terms",
    "section": "",
    "text": "Glossary of ML Terms\n\n\n\n\n\n\n\n\n\n\n\nTerm\nMeaning\nApplication\nKey Benefits\nCommon Libraries/Tools\nCategories\n\n\n\n\nML\nMachine learning\nStudy of statistical algorithms that can learn from data and generalize to unseen data\nFacilitates discovery of complex patterns, enhances predictive modeling, enables large-scale data analysis\nScikit-learn, TensorFlow, PyTorch\nGeneral Concepts\n\n\nEDA\nExploratory data analysis\nUnderstanding data before modeling\nIdentifies patterns, detects anomalies, informs feature selection\nPandas, Matplotlib, Seaborn\nGeneral Concepts\n\n\nNLP\nNatural language processing\nProcessing and analyzing natural language data\nEnables textual data mining, supports linguistic research, automates language understanding tasks\nNLTK, SpaCy, Hugging Face Transformers\nGeneral Concepts\n\n\nOne-hot encoding\nCategorical variable encoding\nConverts categorical data into binary vectors\nHandles categorical data, prevents ordinal relationships\nScikit-learn, Pandas\nGeneral Concepts\n\n\nCross-validation\nModel validation technique\nAssessing model performance\nReduces overfitting, provides reliable performance estimates\nScikit-learn\nModel Evaluation and Optimization\n\n\nOverfitting\nModel performance issue\nOccurs when a model learns noise\nReduces generalization, can be mitigated with regularization\nScikit-learn, TensorFlow\nModel Evaluation and Optimization\n\n\nUnderfitting\nModel performance issue\nOccurs when a model is too simple\nLeads to poor performance on training and test data, needs more complexity\nScikit-learn, TensorFlow\nModel Evaluation and Optimization\n\n\nHyperparameter tuning\nOptimization process\nImproves model performance\nFinds optimal parameters, enhances model accuracy\nScikit-learn, Optuna, Hyperopt\nModel Evaluation and Optimization\n\n\nROC\nReceiver operating characteristic\nEvaluating classification models\nAssesses performance across different thresholds, provides AUC metric\nScikit-learn, Matplotlib\nModel Evaluation and Optimization\n\n\nAUC\nArea under the ROC curve\nEvaluating classification models\nMeasures overall performance of binary classifiers\nScikit-learn, Matplotlib\nModel Evaluation and Optimization\n\n\nF1 Score\nHarmonic mean of precision and recall\nEvaluating classification models\nBalances precision and recall, useful for imbalanced datasets\nScikit-learn\nModel Evaluation and Optimization\n\n\nGradient descent\nOptimization algorithm\nMinimizes loss functions\nEfficiently finds optimal model parameters\nTensorFlow, PyTorch, Scikit-learn\nModel Evaluation and Optimization\n\n\nSVM\nSupport vector machines\nClassification and regression analysis\nEffective in high-dimensional spaces, robust to overfitting with appropriate kernel choice\nScikit-learn, LibSVM\nClassification and Regression Models\n\n\nKNN\nK-nearest neighbors\nClassification and regression\nSimple and intuitive, effective with small datasets\nScikit-learn\nClassification and Regression Models\n\n\nRF\nRandom forest\nClassification and regression\nHandles large datasets, reduces overfitting\nScikit-learn\nClassification and Regression Models\n\n\nXGBoost\nExtreme Gradient Boosting\nClassification and regression\nHigh performance, handles missing data well\nXGBoost library\nClassification and Regression Models\n\n\nAdaBoost\nAdaptive Boosting\nClassification and regression\nImproves accuracy, reduces bias and variance\nScikit-learn\nClassification and Regression Models\n\n\nCNN\nConvolutional neural network\nImage and video recognition\nHigh accuracy in visual tasks, useful in feature extraction, adaptable to various types of image data\nTensorFlow, Keras, PyTorch\nVision Models (Neural Networks)\n\n\nVision Transformer (ViT)\nTransformer architecture for vision tasks\nImage classification, segmentation\nCaptures long-range dependencies, highly parallelizable, effective on large datasets\nHugging Face Transformers, PyTorch, TensorFlow\nVision Models (Neural Networks), Sequence and Text Models (Neural Networks)\n\n\nRNN\nRecurrent neural network\nSequential data processing\nCaptures temporal dependencies, useful in time series analysis\nTensorFlow, PyTorch, Keras\nSequence and Text Models (Neural Networks), Generative Models\n\n\nLSTM\nLong short-term memory\nTime series prediction\nCaptures long-term dependencies, prevents vanishing gradient problem\nTensorFlow, Keras, PyTorch\nSequence and Text Models (Neural Networks), Generative Models\n\n\nTransformers\nModel architecture\nSequence-to-sequence tasks, generative tasks\nCaptures long-range dependencies, highly parallelizable, versatile for various NLP tasks\nHugging Face Transformers, TensorFlow, PyTorch\nSequence and Text Models (Neural Networks), Generative Models\n\n\nGAN\nGenerative adversarial network\nData generation (images, text, etc.)\nGenerates realistic data, useful in image synthesis and text generation\nTensorFlow, PyTorch\nGenerative Models\n\n\nLLMs\nLarge language models\nNatural language understanding and generation\nHandles diverse NLP tasks, pre-trained on vast corpora\nHugging Face Transformers, OpenAI GPT-3, Google BERT\nLarge-Scale Models, Generative Models\n\n\nLMM\nLarge multimodal models\nIntegrates text, image, and other data types\nProvides comprehensive understanding across modalities\nOpenAI CLIP, Hugging Face Transformers\nLarge-Scale Models, Generative Models\n\n\nTransfer learning\nPre-trained model adaptation\nLeveraging existing models for new tasks\nReduces training time, improves performance on small datasets\nTensorFlow, PyTorch, Keras\nAdvanced Techniques and Practices\n\n\nPCA\nPrincipal component analysis\nDimensionality reduction\nReduces dimensionality, aids in visualization of high-dimensional data, retains most variance\nScikit-learn, NumPy\nDimensionality Reduction and Clustering\n\n\nDBSCAN\nDensity-based spatial clustering of applications with noise\nClustering\nIdentifies clusters of arbitrary shape, handles noise\nScikit-learn\nDimensionality Reduction and Clustering\n\n\nt-SNE\nt-distributed stochastic neighbor embedding\nData visualization\nReduces dimensionality for visualization, preserves local structure\nScikit-learn, Multicore-TSNE\nDimensionality Reduction and Clustering\n\n\nDropout\nRegularization technique\nPrevents overfitting in neural networks\nImproves generalization, randomly drops neurons during training\nTensorFlow, Keras, PyTorch\nRegularization Techniques\n\n\nLASSO\nLeast absolute shrinkage and selection operator\nRegression analysis\nPrevents overfitting, performs feature selection\nScikit-learn\nRegularization Techniques, Regression\n\n\nRidge\nRidge regression\nRegression analysis\nPrevents overfitting, handles multicollinearity\nScikit-learn\nRegularization Techniques, Regression\n\n\nElastic Net\nCombination of LASSO and Ridge\nRegression analysis\nCombines benefits of LASSO and Ridge, robust feature selection\nScikit-learn\nRegularization Techniques, Regression",
    "crumbs": [
      "Glossary of ML terms"
    ]
  },
  {
    "objectID": "Applications/index.html",
    "href": "Applications/index.html",
    "title": "Applications",
    "section": "",
    "text": "Discover a curated collection of blogs, papers, and talks which dive into ML applications and lessons learned by practitioners.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Healthcare and Agriculture through Computer Vision\n\n\n\n\n\n\nForums\n\n\nComputer vision\n\n\nUltrasound\n\n\nAgriculture\n\n\nLSTM\n\n\nCNN-LSTM\n\n\nCNN\n\n\nDeep learning\n\n\n\n1. An ultrasound-based method to measure knee kinematics enabled by deep learning 2. Plant breeding in the age of computer vision \n\n\n\n\n\n2024-04-09\n\n\nMatthew Blomquist, Will de la Bretonne\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Model Sharing in the Age of Foundation Models\n\n\n\n\n\n\nForums\n\n\nMultimodal learning\n\n\nFoundation models\n\n\nModel sharing\n\n\nHugging Face\n\n\nLLM\n\n\nLMM\n\n\nLLaVA\n\n\nDeep learning\n\n\n\n1. Model sharing and reproducible ML 2. LLaVA-NeXT and model sharing \n\n\n\n\n\n2024-03-12\n\n\nChris Endemann, Haotian Liu\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Gravitational Waves with AI Insights\n\n\n\n\n\n\nForums\n\n\nPhysics\n\n\nSimulations\n\n\n\n1. Welcome and small group discussions 2. Classifying gravitational wave modes from core-collapse supernovae \n\n\n\n\n\n2024-02-13\n\n\nChris Endemann, Bella Finkel\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Science Communication and Drug Synergy Analysis using GPT\n\n\n\n\n\n\nForums\n\n\nScience communication\n\n\nHealthcare\n\n\nDrug synergy\n\n\nLLM\n\n\nText mining\n\n\n\n1. GPT for Science Communication: User-Interface and Developer Pipeline Approaches 2. Advancing Biomedical Research with GPT-4: A Novel Approach to Drug Synergy Analysis using Text Mining and Classification \n\n\n\n\n\n2023-12-12\n\n\nBen Rush, Jack Freeman\n\n\n\n\n\n\n\n\n\n\n\n\nLLMS in Genomic and Health Coaching\n\n\n\n\n\n\nForums\n\n\nHealthcare\n\n\nClustering\n\n\nDeep learning\n\n\nLLM\n\n\nGenomics\n\n\n\n1. Clustering of genomic sequences of mycoviruses using deep learning 2. Spurring self-improvement and intrinsic motivation using LLMs and reinforcement learning \n\n\n\n\n\n2023-11-07\n\n\nRohan Sontahlia, Michael Roytman\n\n\n\n\n\n\n\n\n\n\n\n\nTime-Series Analysis\n\n\n\n\n\n\nForums\n\n\nTime-series\n\n\nGenomics\n\n\nHealthcare\n\n\n\n1. Computational Methods for Comparative Time Clocks in Early Development and Tissue Regeneration 2. Controlled Differential Equations on Long Sequences via Non-standard Wavelets \n\n\n\n\n\n2023-10-10\n\n\nPeng Jiang, Sourav Pal\n\n\n\n\n\n\n\n\n\n\n\n\nMultimodal Learning\n\n\n\n\n\n\nForums\n\n\nMultimodal learning\n\n\nDeep learning\n\n\nComputer vision\n\n\nHealthcare\n\n\nGenomics\n\n\n\n1. Multimodal learning and analysis for understanding single-cell functional genomics in brains and brain diseases 2. Transforming healthcare: AI-enhanced disease quantification with vision-language models 3. The benefits of early fusion: deeply integrated audio-visual representation learning \n\n\n\n\n\n2023-09-19\n\n\nDaifeng Wang, Zachary Huemann, Pedro Morgado\n\n\n\n\n\n\n\n\n\n\n\n\nExploring AI at UW-Madison\n\n\n\n\n\n\nDeep learning\n\n\nEthics\n\n\nPlaylists\n\n\nMedical imaging\n\n\nAlgorithmic bias\n\n\n\nA summer 2023 webinar series sponsored by the Division of Information Technology and the Data Science Institute.\n\n\n\n\n\n2023-06-23\n\n\nChris Endemann\n\n\n\n\n\n\n\n\n\n\n\n\nML+X Forum\n\n\n\n\n\n\nPlaylists\n\n\n\n Each monthly ML+X forum highlights two ML applications that share a theme followed by communal discussions and project feedback.\n\n\n\n\n\nInvalid Date\n\n\nChris Endemann\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Applications"
    ]
  },
  {
    "objectID": "Applications/Playlists/index.html",
    "href": "Applications/Playlists/index.html",
    "title": "Playlists",
    "section": "",
    "text": "In addition to posting individual, highlighted ML applications from conferences, webinars, etc., the Nexus platform curates a list of playlists where you can explore a larger selection of talks (application focused). In general, all playlists posted here should have at least one corresponding “highlight” posted under Highlights.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nExploring AI at UW-Madison\n\n\n\n\n\n\nDeep learning\n\n\nEthics\n\n\nPlaylists\n\n\nMedical imaging\n\n\nAlgorithmic bias\n\n\n\nA summer 2023 webinar series sponsored by the Division of Information Technology and the Data Science Institute.\n\n\n\n\n\nChris Endemann\n\n\n\n\n\n\n\n\n\n\n\n\nML+X Forum\n\n\n\n\n\n\nPlaylists\n\n\n\n Each monthly ML+X forum highlights two ML applications that share a theme followed by communal discussions and project feedback.\n\n\n\n\n\nChris Endemann\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Applications",
      "Playlists"
    ]
  },
  {
    "objectID": "Applications/Playlists/Exploring-AI-at-UW.html",
    "href": "Applications/Playlists/Exploring-AI-at-UW.html",
    "title": "Exploring AI at UW-Madison",
    "section": "",
    "text": "From the Exploring Artificial Integlligence @ UW-Madison webpage: “From June 23 to September 29, 2023, we were privileged to present a thought-provoking artificial-intelligence (AI) webinar series tailored specifically for UW–Madison.\nIn today’s rapidly evolving world, the importance of AI in our academic environment cannot be overstated. As technological advancements continue to shape our society, we believe it is crucial to explore the opportunities and challenges AI brings to the forefront of higher education.\nThis webinar series aimed to provide a platform for experts and visionaries in the field of AI to share their insights, research and experiences in the classroom, research lab and wider academic community. By delving into topics such as AI ethics, cutting-edge machine learning algorithms, automation and human-machine collaboration, we hoped to foster a deeper understanding of AI’s transformative potential and its implications for higher education.\nThis was a captivating and engaging journey of discovery and innovation. We’re pleased to present recordings of the webinar sessions here.”\nNote: To access the videos, you will need to be a UW-Madison affiliate with a netID."
  },
  {
    "objectID": "Applications/Playlists/Exploring-AI-at-UW.html#about-this-resource",
    "href": "Applications/Playlists/Exploring-AI-at-UW.html#about-this-resource",
    "title": "Exploring AI at UW-Madison",
    "section": "",
    "text": "From the Exploring Artificial Integlligence @ UW-Madison webpage: “From June 23 to September 29, 2023, we were privileged to present a thought-provoking artificial-intelligence (AI) webinar series tailored specifically for UW–Madison.\nIn today’s rapidly evolving world, the importance of AI in our academic environment cannot be overstated. As technological advancements continue to shape our society, we believe it is crucial to explore the opportunities and challenges AI brings to the forefront of higher education.\nThis webinar series aimed to provide a platform for experts and visionaries in the field of AI to share their insights, research and experiences in the classroom, research lab and wider academic community. By delving into topics such as AI ethics, cutting-edge machine learning algorithms, automation and human-machine collaboration, we hoped to foster a deeper understanding of AI’s transformative potential and its implications for higher education.\nThis was a captivating and engaging journey of discovery and innovation. We’re pleased to present recordings of the webinar sessions here.”\nNote: To access the videos, you will need to be a UW-Madison affiliate with a netID."
  },
  {
    "objectID": "Applications/Playlists/Exploring-AI-at-UW.html#questions",
    "href": "Applications/Playlists/Exploring-AI-at-UW.html#questions",
    "title": "Exploring AI at UW-Madison",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html",
    "href": "In-progress/Resources-drafts/Model-sharing.html",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "Model Hub: https://huggingface.co/models\nNavigating the Model Hub: https://huggingface.co/docs/hub/en/models-the-hub\nModel cards\n\nhttps://huggingface.co/docs/hub/en/model-cards\nhttps://huggingface.co/blog/model-cards\n\nUploading a model to Hugging Face: https://huggingface.co/docs/hub/en/models-uploading\n\n\n\n\n\nNavigating the Model Hub: https://huggingface.co/docs/hub/en/models-the-hub\nModels are uploaded with tags associated with\n\ntask\nlibrary (PyTorch, Tensorflow, etc.)\ntraining data\nlanguage (english, spanish, etc.)\nlicense\n\nClicking a model will show you its model card\n\n\n\n\n\nSee: https://huggingface.co/docs/hub/en/model-cards and https://huggingface.co/blog/model-cards\nThe information included in any given model cards is, unfortunately, not well standardized. However, it is best practice to include at least the following pieces of information\n\nInfo on base model (e.g., if your model is finetuned)\nInfo on common model variations\n\nHelp others understand your model within the context of recent developments\n\nModel description\n\ngeneral purpose\narchitecture\n\nInfo on training data\n\nHow the data was collected\nData license and usage terms\nBasic descriptive statistics: number of samples, features, classes, etc. Describe and/or visualize data distribution.\nNote any class imbalance issues. Include assessments of bias and fairness, when possible.\n\nExample: The training dataset used for the facial recognition model might unintentionally be biased, containing predominantly images of people from certain demographic groups (e.g., predominantly light-skinned individuals).\n\n\nThe model’s evaluation results\nIntended uses and limitations\n\nThis is critical for all models, but especially models that can have a downstream impact on people.\nExample: If the model is not designed to handle diverse demographics, it may learn patterns that favor certain groups while performing poorly on others. In this case, the model may have higher accuracy for light-skinned individuals but lower accuracy for darker-skinned individuals.\n\n\n\n\n\n\n\nUploading a model to Hugging Face: https://huggingface.co/docs/hub/en/models-uploading\nAll models are stored as GitHub repositories\nSome frameworks (e.g., PyTorch) have integrations that make it straightforward to upload a model within your model training script\nYou get to decide what information and metadata you want to include in the GitHub repository\n\n\n\n\n\nIs there any way to help control the overall coding environment when sharing a model? For instance, if my goal is to reproduce paper results exactly rather than repurpose a model.\nHow documented should my data be within my model card? Should I save the details for a separate “data card”?\nIf you already have a convenient way to download and load models stored elsewhere (e.g. Zenodo), how much additional benefit is there to refactoring your code to use Hugging Face to host the models?\nWhat is involved in running an interactive demo on the Hugging Face website with your model?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#links",
    "href": "In-progress/Resources-drafts/Model-sharing.html#links",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "Model Hub: https://huggingface.co/models\nNavigating the Model Hub: https://huggingface.co/docs/hub/en/models-the-hub\nModel cards\n\nhttps://huggingface.co/docs/hub/en/model-cards\nhttps://huggingface.co/blog/model-cards\n\nUploading a model to Hugging Face: https://huggingface.co/docs/hub/en/models-uploading"
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#navigating-model-hub",
    "href": "In-progress/Resources-drafts/Model-sharing.html#navigating-model-hub",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "Navigating the Model Hub: https://huggingface.co/docs/hub/en/models-the-hub\nModels are uploaded with tags associated with\n\ntask\nlibrary (PyTorch, Tensorflow, etc.)\ntraining data\nlanguage (english, spanish, etc.)\nlicense\n\nClicking a model will show you its model card"
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#model-cards",
    "href": "In-progress/Resources-drafts/Model-sharing.html#model-cards",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "See: https://huggingface.co/docs/hub/en/model-cards and https://huggingface.co/blog/model-cards\nThe information included in any given model cards is, unfortunately, not well standardized. However, it is best practice to include at least the following pieces of information\n\nInfo on base model (e.g., if your model is finetuned)\nInfo on common model variations\n\nHelp others understand your model within the context of recent developments\n\nModel description\n\ngeneral purpose\narchitecture\n\nInfo on training data\n\nHow the data was collected\nData license and usage terms\nBasic descriptive statistics: number of samples, features, classes, etc. Describe and/or visualize data distribution.\nNote any class imbalance issues. Include assessments of bias and fairness, when possible.\n\nExample: The training dataset used for the facial recognition model might unintentionally be biased, containing predominantly images of people from certain demographic groups (e.g., predominantly light-skinned individuals).\n\n\nThe model’s evaluation results\nIntended uses and limitations\n\nThis is critical for all models, but especially models that can have a downstream impact on people.\nExample: If the model is not designed to handle diverse demographics, it may learn patterns that favor certain groups while performing poorly on others. In this case, the model may have higher accuracy for light-skinned individuals but lower accuracy for darker-skinned individuals."
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#uploading-a-model",
    "href": "In-progress/Resources-drafts/Model-sharing.html#uploading-a-model",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "Uploading a model to Hugging Face: https://huggingface.co/docs/hub/en/models-uploading\nAll models are stored as GitHub repositories\nSome frameworks (e.g., PyTorch) have integrations that make it straightforward to upload a model within your model training script\nYou get to decide what information and metadata you want to include in the GitHub repository"
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#open-questions",
    "href": "In-progress/Resources-drafts/Model-sharing.html#open-questions",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "Is there any way to help control the overall coding environment when sharing a model? For instance, if my goal is to reproduce paper results exactly rather than repurpose a model.\nHow documented should my data be within my model card? Should I save the details for a separate “data card”?\nIf you already have a convenient way to download and load models stored elsewhere (e.g. Zenodo), how much additional benefit is there to refactoring your code to use Hugging Face to host the models?\nWhat is involved in running an interactive demo on the Hugging Face website with your model?"
  },
  {
    "objectID": "In-progress/Resources-drafts/Model-sharing.html#questions",
    "href": "In-progress/Resources-drafts/Model-sharing.html#questions",
    "title": "Model Sharing via Hugging Face",
    "section": "",
    "text": "If you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML+X Nexus: Crowdsourced ML Resources",
    "section": "",
    "text": "Nexus is the ML+X community’s centralized hub for sharing machine learning (ML) resources. Visit the ML+X website to learn more about the community, and join the ML+X google group to stay informed on upcoming community events!\n\nWhat kinds of resources are hosted on Nexus?\nAny content (original or external) that can help make the practice of ML more connected, accessible, efficient, and reproducible is welcome on the Nexus platform! This includes, but is not limited to:\n\n🧠 Educational materials: Explore a library of educational materials (workshops, guides, books, videos, etc.) covering a wide range of ML-related topics, tools, and workflows, from foundational concepts to advanced techniques. These materials offer clear explanations, practical examples, and actionable insights to help you navigate the complexities of ML with confidence.\n🧬 Applications & stories: Discover a curated collection of blogs, papers, and talks which dive into real-world ML applications and lessons learned by practitioners. This section also includes exploratory data analysis (EDA) case studies, which demonstrate the technical and domain knowledge needed to explore data from various fields.\n🛠 Coming soon! Models, code, & data: Learn about popular pretrained & foundation models, useful scripts, and datasets that you can leverage for your next ML project. Learn about their features, how to use them effectively, and see examples of them in action.\n\n\n\nMake a contribution to Nexus!\nThis website is a team effort! We welcome and encourage fellow practitioners to contribute a useful ML resource to Nexus. For instructions on how to contribute, visit How to contribute?.\n\n\nExplore ML Resources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrokking\n\n\n\nDeep learning\n\n\nEmpirical patterns\n\n\nGrokking\n\n\nVideos\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-26\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Python (Carpentries)\n\n\n\nPython\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Machine Learning with Sklearn (Carpentries)\n\n\n\nClassical ML\n\n\nSklearn\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with Keras (Carpentries)\n\n\n\nDeep learning\n\n\nKeras\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with PyTorch (Udacity)\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nWorkshops\n\n\nUdacity\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Deep Learning\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nBooks\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Text Analysis / NLP (Carpentries)\n\n\n\nDeep learning\n\n\nHugging Face\n\n\nText analysis\n\n\nNLP\n\n\nLLM\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of Reproducibility Lecture\n\n\n\nReproducibility\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with GitHub Desktop\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nGuides\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with Git and GitHub (Carpentries)\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nWorkshops\n\n\nCode-along\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut-of-Distribution Detection\n\n\n\nOOD detection\n\n\nTrustworthy ML\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCenter for Highthroughput Computing (CHTC)\n\n\n\nCompute\n\n\nGPU\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-06-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Contribute?\n\n\n\nContribute\n\n\nGuides\n\n\n\n\n\n\n\nML+X\n\n\n2024-06-24\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html",
    "href": "Resources/Guides/How-to-contribute.html",
    "title": "How to Contribute?",
    "section": "",
    "text": "We want Nexus to serve also as a place where members of the community can share their knowledge. This guide answers the question, how to contribute to Nexus?",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#what-kinds-of-resources-are-hosted-on-nexus",
    "href": "Resources/Guides/How-to-contribute.html#what-kinds-of-resources-are-hosted-on-nexus",
    "title": "How to Contribute?",
    "section": "What kinds of resources are hosted on Nexus?",
    "text": "What kinds of resources are hosted on Nexus?\nAny content (original or external) that can help make the practice of ML more connected, accessible, efficient, and reproducible is welcome on the Nexus platform! This includes, but is not limited to:\n\n🧠 Educational materials: Explore a library of educational materials (workshops, guides, books, videos, etc.) covering a wide range of ML-related topics, tools, and workflows, from foundational concepts to advanced techniques. These materials offer clear explanations, practical examples, and actionable insights to help you navigate the complexities of ML with confidence.\n🧬 Applications & stories: Discover a curated collection of blogs, papers, and talks which dive into real-world ML applications and lessons learned by practitioners. This section also includes exploratory data analysis (EDA) case studies, which demonstrate the technical and domain knowledge needed to explore data from various fields.\n🛠 Coming soon! Models, code, & data: Learn about popular pretrained & foundation models, useful scripts, and datasets that you can leverage for your next ML project. Learn about their features, how to use them effectively, and see examples of them in action.",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#need-inspiration-for-a-good-topic-to-post-about",
    "href": "Resources/Guides/How-to-contribute.html#need-inspiration-for-a-good-topic-to-post-about",
    "title": "How to Contribute?",
    "section": "Need inspiration for a good topic to post about?",
    "text": "Need inspiration for a good topic to post about?\nAn ever-expanding list of requested resources can be found on the Issues page (on GitHub). Search for open issues that have the “Resource” label to check out some of our top priorities. If you’d like to tackle a given issue, please comment on the issue to let others know.",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#what-makes-a-good-post",
    "href": "Resources/Guides/How-to-contribute.html#what-makes-a-good-post",
    "title": "How to Contribute?",
    "section": "What makes a good post?",
    "text": "What makes a good post?\nCreating a useful and engaging post for the ML+X Nexus involves a few key elements to ensure it is beneficial for the community. Here are some general guidelines to follow:\n\nClear and concise title\nThe title should accurately reflect the content and main focus of the post. It should be engaging and specific, allowing readers to quickly understand what they can expect.\n\n\nDetailed description\nProvide a comprehensive overview of the resource or topic. This should include:\n\nPurpose and scope: Clearly state what the resource covers and its main objectives. Explain why the content is valuable and how it can help practitioners.\nKey features: Highlight the unique aspects or strengths of the resource. This could include practical examples, interactive elements, or real-world applications.\nStrengths and weaknesses: Provide a balanced view by discussing both the strengths and any potential limitations of the resource. This helps users make informed decisions about whether the resource is right for them.\n\n\n\nPrerequisites\nList any necessary background knowledge or skills required to fully benefit from the resource. This helps set expectations and ensures that users are adequately prepared. Include links to additional resources or tutorials that can help users gain the required knowledge.\n\n\nEstimated time to complete\nOffer an estimate of the time commitment needed to complete the resource. This helps users plan their learning activities and manage their time effectively.\n\n\nAccessibility and usability\nEnsure the resource is easy to access and use. We want the majority of resources on Nexus to be free and open source (with possibly a few rare exceptions for tools/resources in high-demand). Provide clear instructions on how to navigate and utilize the content. If the resource is hosted externally, include a direct link and any necessary login or access information.\n\n\nAdditional related resources\nInclude links to related materials or further readings that can enhance the user’s understanding and provide more in-depth knowledge on the topic. This can include books, articles, other workshops, or case studies. When possible, link to any relevant materials which are already hosted on the Nexus platform.\n\n\nExample of a good posts\nExternal recommendations\n\nWorkshop\nBook\nVideo\n\nOriginal content\n\nGuide",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#how-to-make-a-new-post-with-github",
    "href": "Resources/Guides/How-to-contribute.html#how-to-make-a-new-post-with-github",
    "title": "How to Contribute?",
    "section": "How to make a new post with GitHub?",
    "text": "How to make a new post with GitHub?\n\nGitHub collaboration model\nWe follow GitHub’s collaboration model, so the general idea to make a post or edit a document is the same. The high-level steps include:\n\nCreate an issue announcing your plan to add a resource — see ML+X Nexus Issues\nFork the ML+X-Nexus repository\nClone the forked repository onto your local machine\nCreate a new branch\nWrite the post, commit and push the changes\nMake a pull request\n\nIf you don’t know how to use Git / GitHub already, it can be a little intimidating at first. A friendlier alternative could be to download GitHub desktop and add your post using the instructions provided below. If you’d like to learn more about GitHub Desktop, check out the Version Control with GitHub Desktop guide on Nexus. If you need additional help (and work in a research lab at UW-Madison), you may also seek help at the Data Science Hub’s office hours (“Coding Meetup”).\n\n1. Get Started with GitHub Desktop\n\nGo to the GitHub Desktop website and download the application for your operating system. Install GitHub Desktop by following the on-screen instructions.\nOpen GitHub Desktop and sign in with your GitHub account. If you don’t have one, you will need to create your GitHub account first.\n\n\n\n2. Create an Issue on Nexus GitHub\nBefore you start writing your content, create an issue on the Nexus GitHub to announce your intended addition. This helps the Nexus development team keep track of new contributions and provides an opportunity for feedback.\n\nGo to the Nexus GitHub Issues page\nClick on the New Issue button.\nTitle the issue with the name of your resource, and add a “Resource” label/tag (found on right side panel of issue post).\nDescribe why you think this resource should be included on the Nexus platform.\nWait for feedback: Wait for one of the Nexus developers to provide feedback or comments on your issue before proceeding.\n\n\n\n3. Fork the Repository\n\nGo to the ML+X-Nexus repository on GitHub.\nClick the Fork button at the top-right corner of the page. This will create a copy of the repository under your GitHub account.\n\n\n\n4. Clone the Repository to Your System to Your Local System\n\nFrom your new forked version of the repo on GitHub, click the green Code button to copy the HTTPS URL of the fork\nIn GitHub Desktop, click on File &gt; Clone Repository.\nPaste the URL and click Clone\n\n\n\n5. Create a New Branch\n\nIn GitHub Desktop, click on Branch &gt; New Branch.\nName your new branch descriptively based on the resource type and name (e.g., workshop-introDL, video-NeurIPS2024, etc.).\n\n\n\n6. Write Your Post\n\nOpen your favorite text editor or IDE (e.g., Visual Studio Code, Sublime Text).\nWrite your post in the appropriate format. Follow the guidelines in the next section for writing a good post, making use the template file provided.\n\n\n\n7. Commit and Push Changes\n\nIn GitHub Desktop, you should see your changes listed under Changes.\nWrite a descriptive commit message (e.g., Add new resource: workshop-introDL).\nClick Commit to your-branch-name.\nClick on Repository &gt; Push to push your changes to GitHub.\n\n\n\n8. Make a Pull Request\n\nGo to your forked repository on GitHub.\nClick on the Compare & pull request button.\nEnsure you are merging into the “main” branch of the ML+X-Nexus repository.\nWrite a descriptive title and comment for your pull request.\nClick Create pull request.\n\n\n\n9. Wait for Review\n\nOne of the Nexus developers will review your pull request. They may provide feedback or request changes.\nAddress any feedback and push additional commits as needed.\n\n\n\n\nHow to write the post?\n\nExternal resources\nIf you are adding an external resource, please start with one of the relevant template files linked below. There are comments in each template that will help you make the appropriate edits for your resource. You can also check out how other posts have been formatted by clicking “Improve this page” from a given post’s webpage. This will bring you directly to the qmd file for that post.\n\n“Learn” resource: workshop, book, guide, video lecture, etc.\nApplication - talk/video\n\n\n\nOrginal content\nTo write a post, there are many options: Write it using quarto, rmarkdown, or jupyter. The post could be a new file in the appropriate folder (Resources, ML-stories, or EDA), or a named folder with an index.[ipynb|qmd|rmd|md] extension. In any case, the header of the post needs to be a yaml section with the fields:\n---\ntitle: An Example\ndescription: |\n  An exploratory data analysis example\nauthor: ML+X\ndate-modified: \"last-modified\"\ndate-format: long\ncategories:\n  - EDA\n  - PCA\n---\nThe only fields that need to be changed are title, description, author and the categories. Ideally the categories should match the tags that are already in use in the site, e.g. if tag that we are using for support vector machines is SVM then use that one instead of writing another one like support-vector-machines. You can also check out how other posts have been formatted by clicking “Improve this page” from a given post’s webpage. This will bring you directly to the qmd file for that post.\n\n\n\nWhere to locate your post?\nWe want the site to be constantly evolving with the community, and our intention is to keep the contributions to the site as free as possible. However, we added some sections to structure the site a little bit:\n.\n├── Resources\n│   ├── Books\n│   ├── Blogs\n│   ├── Code\n│   ├── Data \n│   ├── EDA\n│   ├── Guides\n│   ├── Models \n│   ├── Papers\n│   ├── Podcasts \n│   ├── Workshops\n│   ├── Videos\n│   ├── Other \nNote: Some subfolders may not exist yet (e.g., Resources/Podcasts, Resources/Data) since no one has contributed a resource from one of those categories yet (and git doesn’t allow empty folders). Feel free to start one of the missing folders, if applicable. If your resource doesn’t belong to one of the categories listed above, add it to a new Resources/Other subfolder for now.",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#how-to-improve-an-existing-post",
    "href": "Resources/Guides/How-to-contribute.html#how-to-improve-an-existing-post",
    "title": "How to Contribute?",
    "section": "How to improve an existing post?",
    "text": "How to improve an existing post?\nWant to add a code-long exercise to an existing post, add your perspective, or correct a typo? Anyone is welcome and encouraged to suggest improvements to existing materials hosted on Nexus! The most straightforward way to do this is to click “Improve this page” from the post’s webpage on Nexus to suggest your edits. The below steps will walk you through this process.\n\nSteps to improve a post on Nexus via GitHub (no software installation needed):\n\nClick “Improve this page”: This will redirect you to the GitHub repository where the content of the post is stored.\nEdit the file directly on GitHub:\n\nOn the GitHub page, click the pencil icon (✏️) at the top right of the file to edit the content directly in your browser. No need to install any git software!\nMake your changes in the text editor. You can add a code-long exercise, share your perspective, or correct any typos.\n\nCommit your changes:\n\nAfter you have made your edits, scroll down to the “Commit changes” section.\nWrite a brief description of what you changed.\nChoose the option to “Create a new branch for this commit and start a pull request.”\n\nCreate a pull request:\n\nClick the “Propose changes” button.\nYou will be taken to a new page where you can review your changes.\nClick “Create pull request” to submit your changes for review.\n\n\nCongratulations! You have suggested an improvement to a Nexus post. The repository maintainers will review your pull request, and if everything looks good, your changes will be merged into the post.\nNote: While you can make these edits directly on GitHub without any software installation, we recommend all ML practitioners learn git! Check out our git category search resources.",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/How-to-contribute.html#questions",
    "href": "Resources/Guides/How-to-contribute.html#questions",
    "title": "How to Contribute?",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions on how to contribute, please feel free to post to the Nexus Q&A on GitHub. We will improve this guide based on additional questions/comments we receive.",
    "crumbs": [
      "How to contribute?"
    ]
  },
  {
    "objectID": "Resources/Guides/CHTC.html",
    "href": "Resources/Guides/CHTC.html",
    "title": "Center for Highthroughput Computing (CHTC)",
    "section": "",
    "text": "Established in 2006, the Center for High Throughput Computing (CHTC) is committed to democratizing access to powerful computing resources across all research domains. High Throughput Computing (HTC) encompasses a set of principles and techniques designed to optimize computing resource utilization towards solving complex problems. When applied to scientific computing, HTC enhances resource efficiency, automation, and accelerates scientific breakthroughs, including those in machine learning.\nAre you a researcher at UW-Madison seeking to extend your computing capabilities beyond local resources, particularly for machine learning tasks? Request an account now to take advantage of the open computing services offered by the CHTC!"
  },
  {
    "objectID": "Resources/Guides/CHTC.html#about-this-resource",
    "href": "Resources/Guides/CHTC.html#about-this-resource",
    "title": "Center for Highthroughput Computing (CHTC)",
    "section": "",
    "text": "Established in 2006, the Center for High Throughput Computing (CHTC) is committed to democratizing access to powerful computing resources across all research domains. High Throughput Computing (HTC) encompasses a set of principles and techniques designed to optimize computing resource utilization towards solving complex problems. When applied to scientific computing, HTC enhances resource efficiency, automation, and accelerates scientific breakthroughs, including those in machine learning.\nAre you a researcher at UW-Madison seeking to extend your computing capabilities beyond local resources, particularly for machine learning tasks? Request an account now to take advantage of the open computing services offered by the CHTC!"
  },
  {
    "objectID": "Resources/Guides/CHTC.html#chtc-recipes",
    "href": "Resources/Guides/CHTC.html#chtc-recipes",
    "title": "Center for Highthroughput Computing (CHTC)",
    "section": "CHTC “Recipes”",
    "text": "CHTC “Recipes”\nVisit the CHTC Recipes Repository to discover a collection of common CHTC workflows or “recipes”, including those specifically geared towards machine learning tasks.\n\nGPU-based\nExplore our collection of templates tailored for high throughput compute (HTC) systems utilizing GPUs, ideal for accelerating machine learning workflows. These templates streamline the process of job submission, maximizing the utilization of GPU resources for your computational tasks in machine learning. Dive into efficient computing with our GPU-based templates available on GitHub: CHTC GPU Templates\n\n\nContainer Guides\nEmpower your machine learning research endeavors with containerization! CHTC’s guides on Docker and Apptainer for HTC empower researchers to encapsulate their machine learning workflows, dependencies, and environments efficiently. Seamlessly integrate containers into your machine learning computing workflow for enhanced reproducibility and scalability.\n\nDocker Jobs Guide\nApptainer HTC Guide\nPython container\nR container\nPyTorch container\nAlphafold container"
  },
  {
    "objectID": "Resources/Books/index.html",
    "href": "Resources/Books/index.html",
    "title": "Books",
    "section": "",
    "text": "Understanding Deep Learning\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nBooks\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-14\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Learn",
      "Books"
    ]
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_PyTorch.html",
    "href": "Resources/Workshops/Intro-Deeplearning_PyTorch.html",
    "title": "Intro to Deep Learning with PyTorch (Udacity)",
    "section": "",
    "text": "The Intro to Deep Learning with PyTorch workshop from Udacity will walk you through introductory deep learning concepts as well as how to build a neural networks in PyTorch. PyTorch is one of the most popular deep learning frameworks. Known for its speed and more “Pythonic” feel, it is frequently the go-to choice for most researchers. The biggest downside of PyTorch, compared to a high-level framework like Keras, is that it is quite verbose. That is, you’ll need to write a couple hundred lines of code to train and evaluate your neural network. Keras is a great alternative for those who are just getting started with neural networks or those that don’t need to train many models, as you can train/evaluate in just a dozen or so lines of code.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\n\n\n\n\nTBD: Use the Improve this page functionality to add your own estimate!"
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#about-this-resource",
    "href": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#about-this-resource",
    "title": "Intro to Deep Learning with PyTorch (Udacity)",
    "section": "",
    "text": "The Intro to Deep Learning with PyTorch workshop from Udacity will walk you through introductory deep learning concepts as well as how to build a neural networks in PyTorch. PyTorch is one of the most popular deep learning frameworks. Known for its speed and more “Pythonic” feel, it is frequently the go-to choice for most researchers. The biggest downside of PyTorch, compared to a high-level framework like Keras, is that it is quite verbose. That is, you’ll need to write a couple hundred lines of code to train and evaluate your neural network. Keras is a great alternative for those who are just getting started with neural networks or those that don’t need to train many models, as you can train/evaluate in just a dozen or so lines of code.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\n\n\n\n\nTBD: Use the Improve this page functionality to add your own estimate!"
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#questions",
    "href": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#questions",
    "title": "Intro to Deep Learning with PyTorch (Udacity)",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#see-also",
    "href": "Resources/Workshops/Intro-Deeplearning_PyTorch.html#see-also",
    "title": "Intro to Deep Learning with PyTorch (Udacity)",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Deep Learning with Keras: Explore Keras as an alternative deep learning framework\nBook: Understanding Deep Learning - Simon J.D. Prince: This free textbook is a good modern overview of deep learning, and provides colab notebooks to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice. You may find additional details in this book that the workshop only briefly touches on."
  },
  {
    "objectID": "Resources/Workshops/index.html",
    "href": "Resources/Workshops/index.html",
    "title": "Workshops",
    "section": "",
    "text": "UW-Madison has its own local Carpentries community which is actively engaged in developing and teaching new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries and other organizations at UW-Madison, make sure to subscribe to the Data Science @ UW Newsletter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Python (Carpentries)\n\n\n\nPython\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Machine Learning with Sklearn (Carpentries)\n\n\n\nClassical ML\n\n\nSklearn\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with Keras (Carpentries)\n\n\n\nDeep learning\n\n\nKeras\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with PyTorch (Udacity)\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nWorkshops\n\n\nUdacity\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Text Analysis / NLP (Carpentries)\n\n\n\nDeep learning\n\n\nHugging Face\n\n\nText analysis\n\n\nNLP\n\n\nLLM\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with Git and GitHub (Carpentries)\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nWorkshops\n\n\nCode-along\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\n2024-07-11\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Learn",
      "Workshops"
    ]
  },
  {
    "objectID": "Resources/Workshops/Intro-ML_Sklearn.html",
    "href": "Resources/Workshops/Intro-ML_Sklearn.html",
    "title": "Intro to Machine Learning with Sklearn (Carpentries)",
    "section": "",
    "text": "The Intro to Machine Learning with Sklearn workshop from the Carpentries will walk you through introductory machine learning concepts as well as how to implement common ML methods (e.g., regression, clustering, classication) using the popular scikit-learn (“sklearn”) package. Sklearn makes it possible to quickly fit and evaluate many models in just a few lines of code. It also comes with convenient functions needed for nearly all ML pipelines (e.g., train/test split, gridsearchcv). Note: Don’t use Sklearn for neural networks (it is the slowest option!). Instead, explore Keras or PyTorch.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\n\n\n\n\nThis workshop takes approximately 8 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-ML_Sklearn.html#about-this-resource",
    "href": "Resources/Workshops/Intro-ML_Sklearn.html#about-this-resource",
    "title": "Intro to Machine Learning with Sklearn (Carpentries)",
    "section": "",
    "text": "The Intro to Machine Learning with Sklearn workshop from the Carpentries will walk you through introductory machine learning concepts as well as how to implement common ML methods (e.g., regression, clustering, classication) using the popular scikit-learn (“sklearn”) package. Sklearn makes it possible to quickly fit and evaluate many models in just a few lines of code. It also comes with convenient functions needed for nearly all ML pipelines (e.g., train/test split, gridsearchcv). Note: Don’t use Sklearn for neural networks (it is the slowest option!). Instead, explore Keras or PyTorch.\n\n\nLearners are expected to have the following knowledge:\n\nBasic Python programming skills and familiarity with the Pandas package. If you need a refresher, these Introductory Python lesson materials are available for independent study.\n\n\n\n\nThis workshop takes approximately 8 hours to complete.\n\n\n\nThe Carpentries is a global organization of researchers who volunteer their time and effort to create workshops that teach software engineering and data analysis skills to other researchers. UW-Madison has its own local Carpentries community which is actively engaged in developing new ML/AI workshops. To be notified of upcoming workshops offered by the Carpentries, make sure to subscribe to the Data Science @ UW Newsletter. The Intro Deep Learning workshop is typically taught in May each year.\n\n\n\nAll Carpentries lessons are published as open source educational materials. You are welcome and encouraged to visit the lesson materials to work through them on your own. If you are involved with a research lab at UW-Madison campus, you may attend Coding Meetup (Tue/Thur, 2:30-4:30pm) to get help working through the materials."
  },
  {
    "objectID": "Resources/Workshops/Intro-ML_Sklearn.html#questions",
    "href": "Resources/Workshops/Intro-ML_Sklearn.html#questions",
    "title": "Intro to Machine Learning with Sklearn (Carpentries)",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Workshops/Intro-ML_Sklearn.html#see-also",
    "href": "Resources/Workshops/Intro-ML_Sklearn.html#see-also",
    "title": "Intro to Machine Learning with Sklearn (Carpentries)",
    "section": "See also",
    "text": "See also\n\nWorkshop: Intro to Deep Learning with Keras: Once you master sklearn, start using Keras to build neural networks quickly.\nWorkshop: Intro to Deep Learning with PyTorch: Explore PyTorch as an alternative deep learning framework (faster but more verbose than Keras)\nBook: Understanding Deep Learning - Simon J.D. Prince: This free textbook is a good modern overview of deep learning, and provides colab notebooks to explore deep learning concepts and implementations. The book uses PyTorch as its framework of choice. You may find additional details in this book that the workshop only briefly touches on."
  },
  {
    "objectID": "Resources/Videos/Reproducibility-overview.html",
    "href": "Resources/Videos/Reproducibility-overview.html",
    "title": "Overview of Reproducibility Lecture",
    "section": "",
    "text": "Dr. Sarah Stevens’ lecture highlights the critical importance of reproducibility in computational and data science projects. She also shares best practices to ensure reproducible results including:\n\nHow to organize your project\nGood names for files/folders\nDocumenting your work and README files\nHow to organize data in spreadsheets and use data dictionaries\nAutomation with scripts\nVersion control\nLicensing\nCreating backups"
  },
  {
    "objectID": "Resources/Videos/Reproducibility-overview.html#about-this-resource",
    "href": "Resources/Videos/Reproducibility-overview.html#about-this-resource",
    "title": "Overview of Reproducibility Lecture",
    "section": "",
    "text": "Dr. Sarah Stevens’ lecture highlights the critical importance of reproducibility in computational and data science projects. She also shares best practices to ensure reproducible results including:\n\nHow to organize your project\nGood names for files/folders\nDocumenting your work and README files\nHow to organize data in spreadsheets and use data dictionaries\nAutomation with scripts\nVersion control\nLicensing\nCreating backups"
  },
  {
    "objectID": "Resources/Videos/Reproducibility-overview.html#questions",
    "href": "Resources/Videos/Reproducibility-overview.html#questions",
    "title": "Overview of Reproducibility Lecture",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/Videos/Reproducibility-overview.html#see-also",
    "href": "Resources/Videos/Reproducibility-overview.html#see-also",
    "title": "Overview of Reproducibility Lecture",
    "section": "See also",
    "text": "See also\n\nGuide: Version Control with GitHub Desktop: GitHub Desktop is a graphical user interface (GUI) application that simplifies the use of Git and GitHub. It is designed for users who prefer not to use the command line interface, offering a more intuitive and visual approach to version control. With GitHub Desktop, you can easily perform common Git tasks such as committing changes, creating branches, and resolving merge conflicts, all within a user-friendly interface.\nWorkshop: Intro to Version Control with Git: If you’re curious to learn how to use Git via shell commands (or just want to become more fluent with Git), check out this YouTube playlist from the Data Science Hub!"
  },
  {
    "objectID": "Resources/Videos/Grokking.html",
    "href": "Resources/Videos/Grokking.html",
    "title": "Grokking",
    "section": "",
    "text": "The verb, “to grok”, was originally coined by Robert A. Heinlein in his 1961 science fiction novel “Stranger in a Strange Land,” where it meant to understand something so thoroughly that it becomes a part of oneself. In the context of machine learning, “grokking” refers to the phenomenon whereby a model, after extensive training, suddenly shifts from merely memorizing data to achieving a deep and intuitive understanding, allowing it to generalize effectively to new, unseen data. Observing this phenomenon requires a significantly large increase in training iterations, often far beyond the usual training duration expected for a model to reach acceptable performance. This prolonged training period initially shows no improvement in generalization, making the eventual transition to grokking both surprising and significant.\nThe grokking phenomenon was recently investigated in a notable paper from OpenAI (Power et al., 2021). The video you’ll be watching will explain OpenAI’s findings on this transition to generalization, highlighting the dramatic increase in iterations needed and providing a deeper understanding of the process and its implications for developing more robust and reliable machine learning models."
  },
  {
    "objectID": "Resources/Videos/Grokking.html#about-this-resource",
    "href": "Resources/Videos/Grokking.html#about-this-resource",
    "title": "Grokking",
    "section": "",
    "text": "The verb, “to grok”, was originally coined by Robert A. Heinlein in his 1961 science fiction novel “Stranger in a Strange Land,” where it meant to understand something so thoroughly that it becomes a part of oneself. In the context of machine learning, “grokking” refers to the phenomenon whereby a model, after extensive training, suddenly shifts from merely memorizing data to achieving a deep and intuitive understanding, allowing it to generalize effectively to new, unseen data. Observing this phenomenon requires a significantly large increase in training iterations, often far beyond the usual training duration expected for a model to reach acceptable performance. This prolonged training period initially shows no improvement in generalization, making the eventual transition to grokking both surprising and significant.\nThe grokking phenomenon was recently investigated in a notable paper from OpenAI (Power et al., 2021). The video you’ll be watching will explain OpenAI’s findings on this transition to generalization, highlighting the dramatic increase in iterations needed and providing a deeper understanding of the process and its implications for developing more robust and reliable machine learning models."
  },
  {
    "objectID": "Resources/Videos/Grokking.html#questions",
    "href": "Resources/Videos/Grokking.html#questions",
    "title": "Grokking",
    "section": "Questions?",
    "text": "Questions?\nIf you any lingering questions about this resource, please feel free to post to the Nexus Q&A on GitHub. We will improve materials on this website as additional questions come in."
  },
  {
    "objectID": "Resources/index.html",
    "href": "Resources/index.html",
    "title": "Learn",
    "section": "",
    "text": "Explore a library of educational materials (workshops, guides, books, videos, etc.) covering a wide range of ML-related topics, tools, and workflows, from foundational concepts to advanced techniques. These materials offer clear explanations, practical examples, and actionable insights to help you navigate the complexities of ML with confidence.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrokking\n\n\n\nDeep learning\n\n\nEmpirical patterns\n\n\nGrokking\n\n\nVideos\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Python (Carpentries)\n\n\n\nPython\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Machine Learning with Sklearn (Carpentries)\n\n\n\nClassical ML\n\n\nSklearn\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with Keras (Carpentries)\n\n\n\nDeep learning\n\n\nKeras\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Deep Learning with PyTorch (Udacity)\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nWorkshops\n\n\nUdacity\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Deep Learning\n\n\n\nDeep learning\n\n\nPyTorch\n\n\nBooks\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Text Analysis / NLP (Carpentries)\n\n\n\nDeep learning\n\n\nHugging Face\n\n\nText analysis\n\n\nNLP\n\n\nLLM\n\n\nWorkshops\n\n\nCarpentries\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of Reproducibility Lecture\n\n\n\nReproducibility\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with GitHub Desktop\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nGuides\n\n\nCode-along\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with Git and GitHub (Carpentries)\n\n\n\nReproducibility\n\n\nGit/GitHub\n\n\nWorkshops\n\n\nCode-along\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut-of-Distribution Detection\n\n\n\nOOD detection\n\n\nTrustworthy ML\n\n\nVideos\n\n\n\n\n\n\n\nChris Endemann\n\n\nJuly 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCenter for Highthroughput Computing (CHTC)\n\n\n\nCompute\n\n\nGPU\n\n\nGuides\n\n\n\n\n\n\n\nChris Endemann\n\n\nJune 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Contribute?\n\n\n\nContribute\n\n\nGuides\n\n\n\n\n\n\n\nML+X\n\n\nJune 24, 2024\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Learn"
    ]
  }
]