---
title: "Interpretable Machine Learning"
author: 
  - name: Peter Cruz Parrilla 
    email: cruzparrilla@wisc.edu 

date: 2025-08-18 # enter today's date as YYYY-MM-DD
date-format: long # leave as is
image: "../../../images/Interpretable_Machine_Learning.jpg"

categories: 
  - Books # always include
  - Deep learning
  - Regression
  - Decision trees
  - Visualization 
  - Interpretability 
---
## About this resource

[Interpretable Machine Learning (IML)](https://christophm.github.io/interpretable-ml-book/interpretability.html) provides a concise and substantially deep breakdown of many classic machine learning models that serve as the foundation for most machine learning applications today. In a field where it's easy to be amazed by the performance of "blackbox" models, it's important for both beginners and advanced practitioners to understand the sources of success and constraint for a given model in a given application. These details not only improve our ability to make great models but also to extract information that might inform the framing of the problem, the use of the tools, or even the science behind the problem. In this book, you will not only explore the important mathematical and algorithmic structrure of models and the importance of their features on the outputs, but you will also learn model-agnostic ways to evaluate a model's performance. 

### From the author, Christoph Molnar

> Interpretable Machine Learning, or Explainable AI, has really exploded as a field around 2015 ([Molnar, Casalicchio, and Bischl 2020](https://doi.org/10.1007/978-3-030-65965-3_28)). Especially the subfield of model-agnostic interpretability, which offers methods that work for any model, gained a lot of attention. New methods for the interpretation of machine learning models are still being published at breakneck speed. To keep up with everything that is published would be madness and simply impossible. Thatâ€™s why you will not find the most novel and fancy methods in this book, but established methods and basic concepts of machine learning interpretability. These basics prepare you for making machine learning models interpretable. Internalizing the basic concepts also empowers you to better understand and evaluate any new paper on interpretability published on the pre-print server arxiv.org in the last 5 minutes since you began reading this book (I might be exaggerating the publication rate).

#### Prerequisites

- Basic understanding of statistics, linear algebra, and calculus
- Basic understanding of machine learning concepts (loss functions, feature spaces, etc.)

#### Estimated time to complete 

**TBD**: Use the [Improve this page](https://github.com/UW-Madison-DataScience/ML-X-Nexus/edit/main/Learn/Books/{Name}.qmd) functionality to add your own estimate!

## Questions?
If you any lingering questions about this resource, please feel free to post to the [Nexus Q&A](https://github.com/UW-Madison-DataScience/ML-X-Nexus/discussions/categories/q-a) on GitHub. We will improve materials on this website as additional questions come in.

## See also
<!-- MARKDOWN COMMENT: Please Check the existing resources on Nexus to see if any other related resources (e.g., related books/videos, blog posts commenting on the resource, alternative approaches/frameworks, etc.) should be linked below. You may also link to resources which aren't currently on the Nexus platform, if applicable. If you're feeling ambitious, you may wish to post those to Nexus as well!  -->
- [Introduction to Statistical Learning](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Books/Intro-StatisticalLearning_JamesGareth-DanielaWitten-HastieTrevor-TibshiraniRob.html): An introduction to the topics explored in IML. 
- [Trustworthy AI Workshop](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Workshops/TrustworthyAI_Explainability-Bias-Fairness-OODdetection.html). A workshop to apply and explore what you've learned in this book while obtaining additional perspectives about explainability and trustworthiness in AI.
