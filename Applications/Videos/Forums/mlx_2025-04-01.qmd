---
title: "Harnessing the Power of Foundation Models for Healthcare and Life Sciences"
date: 2025-04-01
author:
  - "Jameson Merkow"
image: "https://img.youtube.com/vi/SdehaakpRtw/maxresdefault.jpg"

language: 
  title-block-author-single: "Presenter"
  title-block-published: "Date"

categories:
  - Videos
  - ML+X
  - Healthcare
  - Medical imaging
  - Foundation models
  - Multimodal learning
  - Deep learning
  - Image data
  - Computer vision
  - Retrieval
  - Zero-shot learning
  - LLM
  - Microsoft Copilot
  - Azure
---

## About this resource

Jameson Merkow, AI engineer at Microsoft, presents an overview of recent advances in applying foundation models to healthcare and life sciences. This forum explores the use of multimodal embedding models, large language models (LLMs), and Azure-integrated tools to support clinical workflows and biomedical research.

### Microsoft's healthcare AI offerings
Jameson introduces a suite of tools available through Microsoft's AI Foundry and Azure ML:

- **MedImage Insight (MI2)**: A powerful multimodal embedding model trained across nine medical imaging modalities.
- **MedImage Parse**: A segmentation model that responds to natural language prompts across modalities.
- **CXR ReportGen**: An image-to-text model that outputs structured radiology findings and highlights supporting regions in images.

All tools are open source and deployable within a secure, tenant-controlled Azure environment.

### Applications and use cases
Jameson covers a range of use cases, including:

- Image classification using pretrained embeddings or lightweight adapters.
- Outlier detection for clinical trial QC and data curation.
- Survival prediction from paired MRI and histopathology data using multimodal fusion.
- Image search across 2D, 3D, and cross-modality benchmarks.
- Integration with multi-agent systems for orchestrating model calls and generating clinical reports.
- Drift monitoring using multimodal embeddings and patient metadata.

### Why this matters
Rather than retraining LLMs for each medical task, Microsoft's approach combines task-specific vision/language models with general-purpose reasoning agents. This modular strategy enables faster deployment, clearer interpretability, and easier fine-tuning across domains.

{{< video https://www.youtube.com/watch?v=SdehaakpRtw&t=1136s >}}

## See also
- [MedImage Insight (MI2) Blog](https://techcommunity.microsoft.com/blog/healthcareandlifesciencesblog/discovering-the-power-of-finetuning-medimageinsight-on-your-data/4395057): Read more about Microsoft's open medical embedding model.
- [ChestX-ray14 Dataset](https://paperswithcode.com/dataset/chestx-ray8): A benchmark for image-to-text and classification tasks.
- [**Talk**: Automating Scientific Discovery](https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/Videos/Forums/mlx_2025-03-04.html): Another ML+X forum presentation on multimodal learning in biology and literature.
