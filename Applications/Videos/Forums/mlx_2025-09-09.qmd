---
title: "AI's Environmental Footprint: Insights and Actions"
date: 2025-09-09
author:
  - "Chris Endemann"
  - "Nidhal Jegham"
image: "https://img.youtube.com/vi/2dCQS1jAbUo/maxresdefault.jpg"

language:
  title-block-author-single: "Presenter"
  title-block-author-plural: "Presenters"
  title-block-published: "Date"

categories:
  - Videos
  - ML+X
  - Ethical AI
  - Trustworthy AI
  - Benchmarking
  - LLM
  - RAG
  - Retrieval
  - Cloud
  - GPU
---

## About this resource
This forum explores how machine learning practitioners can measure and reduce the environmental costs of AI. It pairs two complementary efforts: one that retrieves emissions and cost data from sustainability reports using RAG, and another that benchmarks energy, water, and carbon footprints across large language models.

1. **WattBot: Estimating AI Emissions and Costs with RAG — Chris Endemann** [02:24](https://www.youtube.com/watch?v=2dCQS1jAbUo&t=144s){target=_blank}  
   Chris introduces WattBot, a Kaggle challenge and retrieval-augmented generation (RAG) framework for estimating AI emissions and compute costs. Using 35+ papers and 300+ curated Q&A pairs, teams build systems that return citation-backed answers or explicitly state when evidence is missing—promoting transparency and reproducibility in sustainability reporting.  
   - **Kaggle challenge**: [kaggle.com/competitions/WattBot2025/overview](https://www.kaggle.com/competitions/WattBot2025/overview)

2. **How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference — Nidhal Jegham** [09:07](https://www.youtube.com/watch?v=2dCQS1jAbUo&t=547s){target=_blank}  
   Nidhal presents a reproducible framework to estimate per-request energy, water, and carbon use for open and proprietary LLMs. The method combines hardware assumptions (A100–H200 GPUs), data center multipliers (PUE, WUE, CIF), and a DEA-style efficiency score that balances model accuracy against environmental cost.  
   - **Preprint**: [https://arxiv.org/abs/2505.09598](https://arxiv.org/abs/2505.09598)  
   - **Dashboard**: [https://app.powerbi.com/view?r=eyJr9](https://app.powerbi.com/view?r=eyJrIjoiZjVmOTI0MmMtY2U2Mi00ZTE2LTk2MGYtY2ZjNDMzODZkMjlmIiwidCI6IjQyNmQyYThkLTljY2QtNDI1NS04OTNkLTA2ODZhMzJjMTY4ZCIsImMiOjF9)

### Key points
- Data center efficiency and GPU generation (A100–H200) drive impact as much as model size.  
- Environmental multipliers like PUE (Power Usage Effectiveness) and WUE (Water Usage Effectiveness) are critical to cross-site comparisons.
- Model retraining cycles and deployment refreshes (fine-tuning and re-optimization) add hidden costs.  
- Efficiency is not absolute: the Jevons paradox applies—lower per-query cost can increase overall usage.  
- Current reporting lacks unified standards; the EU AI Act is the first major policy requiring disclosure.  
- U.S. regulation remains minimal, making voluntary transparency efforts (like Mistral's) especially important.  
- Renewable energy sourcing and liquid cooling are among the most actionable interventions.  
- Academic and industry collaborations can close data gaps through open benchmarking.

**Discussion takeaways**
- Aggregate usage, not single-query cost, drives total environmental footprint.  
- Publishing carbon and water data in model cards could normalize sustainability reporting.  
- Reporting environmental impact alongside accuracy metrics is an emerging best practice.  
- Community-led reproducibility efforts (like WattBot) help standardize sustainability benchmarks.


{{< video https://www.youtube.com/watch?v=2dCQS1jAbUo&t >}}

## See also  
- [**Notebook**: Exploring RAG with Romeo and Juliet](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Notebooks/2025-05-07_RAG-Romeo-Juliet.html): Learn how to build an end-to-end retrieval augmented generation (RAG) pipeline using Shakespeare's Romeo and Juliet as example text.
- [**Video Archive**: ML+X forum archive](https://uw-madison-datascience.github.io/ML-X-Nexus/Applications/Videos/Forums/): Check out other recorded forums from ML+X.
